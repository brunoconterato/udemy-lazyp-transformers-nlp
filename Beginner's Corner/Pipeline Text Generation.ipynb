{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: transformers in /home/bruno/anaconda3/envs/gpt/lib/python3.9/site-packages (4.31.0)\n",
      "Requirement already satisfied: packaging>=20.0 in /home/bruno/anaconda3/envs/gpt/lib/python3.9/site-packages (from transformers) (22.0)\n",
      "Requirement already satisfied: filelock in /home/bruno/anaconda3/envs/gpt/lib/python3.9/site-packages (from transformers) (3.9.0)\n",
      "Requirement already satisfied: safetensors>=0.3.1 in /home/bruno/anaconda3/envs/gpt/lib/python3.9/site-packages (from transformers) (0.3.1)\n",
      "Requirement already satisfied: numpy>=1.17 in /home/bruno/anaconda3/envs/gpt/lib/python3.9/site-packages (from transformers) (1.21.5)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /home/bruno/anaconda3/envs/gpt/lib/python3.9/site-packages (from transformers) (2022.7.9)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.14.1 in /home/bruno/anaconda3/envs/gpt/lib/python3.9/site-packages (from transformers) (0.16.4)\n",
      "Requirement already satisfied: tqdm>=4.27 in /home/bruno/anaconda3/envs/gpt/lib/python3.9/site-packages (from transformers) (4.64.1)\n",
      "Requirement already satisfied: requests in /home/bruno/anaconda3/envs/gpt/lib/python3.9/site-packages (from transformers) (2.28.1)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /home/bruno/anaconda3/envs/gpt/lib/python3.9/site-packages (from transformers) (6.0)\n",
      "Requirement already satisfied: tokenizers!=0.11.3,<0.14,>=0.11.1 in /home/bruno/anaconda3/envs/gpt/lib/python3.9/site-packages (from transformers) (0.13.3)\n",
      "Requirement already satisfied: fsspec in /home/bruno/anaconda3/envs/gpt/lib/python3.9/site-packages (from huggingface-hub<1.0,>=0.14.1->transformers) (2022.11.0)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /home/bruno/anaconda3/envs/gpt/lib/python3.9/site-packages (from huggingface-hub<1.0,>=0.14.1->transformers) (4.4.0)\n",
      "Requirement already satisfied: charset-normalizer<3,>=2 in /home/bruno/anaconda3/envs/gpt/lib/python3.9/site-packages (from requests->transformers) (2.0.4)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /home/bruno/anaconda3/envs/gpt/lib/python3.9/site-packages (from requests->transformers) (1.26.14)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /home/bruno/anaconda3/envs/gpt/lib/python3.9/site-packages (from requests->transformers) (3.4)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/bruno/anaconda3/envs/gpt/lib/python3.9/site-packages (from requests->transformers) (2022.12.7)\n"
     ]
    }
   ],
   "source": [
    "!pip install transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2023-07-18 19:16:29--  https://raw.githubusercontent.com/lazyprogrammer/machine_learning_examples/master/hmm_class/robert_frost.txt\n",
      "Resolvendo raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.111.133, 185.199.108.133, 185.199.109.133, ...\n",
      "Conectando-se a raw.githubusercontent.com (raw.githubusercontent.com)|185.199.111.133|:443... conectado.\n",
      "A requisição HTTP foi enviada, aguardando resposta... 200 OK\n",
      "Tamanho: 56286 (55K) [text/plain]\n",
      "Salvando em: “robert_frost.txt”\n",
      "\n",
      "robert_frost.txt    100%[===================>]  54,97K  --.-KB/s    em 0,04s   \n",
      "\n",
      "2023-07-18 19:16:30 (1,28 MB/s) - “robert_frost.txt” salvo [56286/56286]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!wget -nc https://raw.githubusercontent.com/lazyprogrammer/machine_learning_examples/master/hmm_class/robert_frost.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import pipeline, set_seed\n",
    "\n",
    "import textwrap\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from pprint import pprint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!cat robert_frost.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "lines = [line.rstrip() for line in open('robert_frost.txt')]\n",
    "# filter empty lines\n",
    "lines = [line for line in lines if len(line) > 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Two roads diverged in a yellow wood,',\n",
       " 'And sorry I could not travel both',\n",
       " 'And be one traveler, long I stood',\n",
       " 'And looked down one as far as I could',\n",
       " 'To where it bent in the undergrowth;',\n",
       " 'Then took the other, as just as fair,',\n",
       " 'And having perhaps the better claim',\n",
       " 'Because it was grassy and wanted wear,',\n",
       " 'Though as for that the passing there',\n",
       " 'Had worn them really about the same,']"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lines[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No model was supplied, defaulted to gpt2 and revision 6c0e608 (https://huggingface.co/gpt2).\n",
      "Using a pipeline without specifying a model name and revision in production is not recommended.\n"
     ]
    }
   ],
   "source": [
    "gen = pipeline(\"text-generation\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "set_seed(1234)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Two roads diverged in a yellow wood,'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lines[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "/home/bruno/anaconda3/envs/gpt/lib/python3.9/site-packages/transformers/generation/utils.py:1369: UserWarning: Using `max_length`'s default (50) to control the generation length. This behaviour is deprecated and will be removed from the config in v5 of Transformers -- we recommend using `max_new_tokens` to control the maximum length of the generation.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[{'generated_text': 'Two roads diverged in a yellow wood, which they had left behind a few yards from where they had cut from. At the end of the road stood a tall red pole and, just out of view, the white-lipped man could see'}]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gen(lines[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'generated_text': 'Two roads diverged in a yellow wood, which they had left '\n",
      "                    'behind a few yards from where they had cut from. At the '\n",
      "                    'end of the road stood a tall red pole and, just out of '\n",
      "                    'view, the white-lipped man could see'}]\n"
     ]
    }
   ],
   "source": [
    "pprint(_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'generated_text': 'Two roads diverged in a yellow wood, and each turned into '\n",
      "                    'a narrow black hole. It became'}]\n"
     ]
    }
   ],
   "source": [
    "pprint(gen(lines[0], max_length=20))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'generated_text': 'Two roads diverged in a yellow wood, about 200 yards from '\n",
      "                    'the beach.\\n'\n",
      "                    '\\n'\n",
      "                    'Then she'},\n",
      " {'generated_text': 'Two roads diverged in a yellow wood, just across from a '\n",
      "                    'house and a park.\\n'\n",
      "                    '\\n'},\n",
      " {'generated_text': 'Two roads diverged in a yellow wood, with a '\n",
      "                    'black-and-white line running west to'}]\n"
     ]
    }
   ],
   "source": [
    "pprint(gen(lines[0], num_return_sequences=3, max_length=20))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def wrap(x):\n",
    "    return textwrap.fill(x, replace_whitespace=False, fix_sentence_endings=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Two roads diverged in a yellow wood, where a small boy wandered off to\n",
      "chase another boy, who was on his way down the road.  He\n"
     ]
    }
   ],
   "source": [
    "out = gen(lines[0], max_length=30)\n",
    "print(wrap(out[0]['generated_text']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "And be one traveler, long I stood\n"
     ]
    }
   ],
   "source": [
    "print(lines[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Two roads diverged in a yellow wood, where a small boy wandered off to\n",
      "chase another boy, who was on his way down the road.\n",
      "And be one\n",
      "traveler, long I stood in the streets and told them it was so on\n",
      "earth.\n",
      "So the girl went at my feet, and\n"
     ]
    }
   ],
   "source": [
    "prev = \"Two roads diverged in a yellow wood, where a small boy wandered off to\" \\\n",
    "    \" chase another boy, who was on his way down the road.\"\n",
    "    \n",
    "out = gen(prev + '\\n' + lines[2], max_length = 60)\n",
    "print(wrap(out[0]['generated_text']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Two roads diverged in a yellow wood, where a small boy wandered off\n",
      "to\n",
      "chase another boy, who was on his way down the road.\n",
      "And be one\n",
      "traveler, long I stood in the streets and told them it was so on\n",
      "earth.\n",
      "\n",
      "To where it bent in the undergrowth; and, as though it felt\n",
      "all free;\n",
      "\n",
      "I turned and stood, and told them—\n",
      "\n",
      "I\n"
     ]
    }
   ],
   "source": [
    "prev = \"\"\"\n",
    "Two roads diverged in a yellow wood, where a small boy wandered off to\n",
    "chase another boy, who was on his way down the road.\n",
    "And be one\n",
    "traveler, long I stood in the streets and told them it was so on\n",
    "earth.\n",
    "\"\"\"\n",
    "    \n",
    "out = gen(prev + '\\n' + lines[4], max_length = 90)\n",
    "print(wrap(out[0]['generated_text']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Neural networks with attention have been used with great success in\n",
      "natural language processing.  A number of these methods have now\n",
      "appeared in some applications for this purpose.  However, no longer is\n",
      "there any practical use of these methods.  This paper seeks to provide\n",
      "a practical understanding of what networks would have practical\n",
      "applications, including those needed using such methods on a high\n",
      "frequency basis.  Based on theoretical theoretical understanding, it\n",
      "is decided that no network application would be able to deliver a\n",
      "standardised neural network.\n",
      "\n",
      "Materials and Methods Data from 19\n",
      "studies conducted by participants to date include: 2,038 [60%; 1.5%\n",
      "error rate]; 1,020 [48%; 1.7% error rate]; 10,000 [35%; 1.5% error\n",
      "rate]; 2,564 [35%; 1.2% error rate] participants\n",
      "\n",
      "Methodological data\n",
      "including nonverbal speech processing was analysed by the data\n",
      "analysis framework, Averaged SPM, using a standard multi-agent\n",
      "analysis framework.  We used ANOVA with p-value <0.05 for all P<0.01\n",
      "(p = 0.03), with a significant F(1,32) for categorical measures and a\n",
      "p<0.05 for all outcomes, followed by two-sided P < 0.01 for all\n",
      "outcomes for each type of interaction between participants and their\n",
      "data analysis procedure.\n",
      "\n",
      "Frequency of participants used the network\n",
      "protocol.  Participants in the first group and participants in the\n",
      "second group have been\n"
     ]
    }
   ],
   "source": [
    "prompt = \"Neural networks with attention have been used with great success\"  + \\\n",
    "  \" in natural language processing.\"\n",
    "  \n",
    "out = gen(prompt, max_length=300)\n",
    "print(wrap(out[0]['generated_text']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "gpt",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
