{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Let's build the transformer's encoder"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 0. Init"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hyperparameters Here\n",
    "BATCH_SIZE = 128\n",
    "T = 80                                  # sentence length\n",
    "D_K = 16\n",
    "D_V = 16\n",
    "D_MODEL = 128\n",
    "H = 8\n",
    "VOCAB_SIZE = 10\n",
    "N_MHA_BLOCKS_ENCODER = 6\n",
    "N_CLASSES = 2                          # classes of classifier\n",
    "\n",
    "# device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "device = \"cpu\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Attention"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.0900, 0.2447, 0.6652],\n",
      "        [0.0900, 0.2447, 0.6652]])\n"
     ]
    }
   ],
   "source": [
    "# Test softmax x axis:\n",
    "matrix = torch.tensor([[1.0, 2.0, 3.0], [4.0, 5.0, 6.0]])\n",
    "\n",
    "softmaxed_matrix = F.softmax(matrix, dim=1)\n",
    "\n",
    "print(softmaxed_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def repeat(x: torch.Tensor, n: int):\n",
    "    # make shape (n, 1, 1, ...) --> quantity of 1's must be len(x.shape)\n",
    "    # for example, if shape of x is (3, 4, 8), shapee must be (n, 1, 1, 1)\n",
    "    tuple_ones = tuple(\n",
    "        (torch.tensor(x.shape) / torch.tensor(x.shape)).numpy().astype(int)\n",
    "    )\n",
    "    # print((n, *tuple_ones))\n",
    "    return x.unsqueeze(0).repeat((n, *tuple_ones))\n",
    "\n",
    "\n",
    "def batched_matmul(x_batched, W):\n",
    "    # # Assuming x_batched.shape == (batch_size, T, d_model)\n",
    "    # # and W.shape == (d_model, d)\n",
    "    # batch_size, T, d_model = x_batched.shape\n",
    "    # d = W.shape[1]\n",
    "\n",
    "    # # Reshape x_batched to (batch_size * T, d_model)\n",
    "    # x_reshaped = x_batched.reshape(-1, d_model)\n",
    "\n",
    "    # # Perform matrix multiplication\n",
    "    # result = torch.matmul(x_reshaped, W)\n",
    "\n",
    "    # # Reshape the result back to (batch_size, T, d)\n",
    "    # result = result.reshape(batch_size, T, d)\n",
    "\n",
    "    # return result\n",
    "\n",
    "    # batch_size = x_batched.shape[0]\n",
    "    # W_repeated = W.unsqueeze(0).repeat((batch_size, 1, 1))\n",
    "    W_repeated = repeat(W, n=x_batched.shape[0])\n",
    "    \n",
    "    return torch.bmm(x_batched, W_repeated)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Attention(nn.Module):\n",
    "    \"\"\" Convention from: https://www.udemy.com/course/data-science-transformers-nlp/learn/lecture/32255056#overview\n",
    "    In our convention, K, Q and V are learneable, different from the \"Attention is all you need\" paper.\n",
    "    \"\"\"\n",
    "    def __init__(self, T: int, d_K, d_V, d_model: int, *args, **kwargs) -> None:\n",
    "        super().__init__(*args, **kwargs)\n",
    "        # define a torch 2d tensor initialized normally\n",
    "        self.W_K = torch.normal(mean=0, std=0.01, size=(d_model, d_K), requires_grad=True)\n",
    "        self.W_Q = torch.normal(mean=0, std=0.01, size=(d_model, d_K), requires_grad=True)\n",
    "        self.W_V = torch.normal(mean=0, std=0.01, size=(d_model, d_V), requires_grad=True)\n",
    "        self.mask = None\n",
    "\n",
    "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
    "        # Shapes:\n",
    "        # W_K (d_model, d_K)\n",
    "        # x is a 3d tensor (batch x T x d_model)\n",
    "\n",
    "        # W_K.T ->  (1, d_k x d_model)\n",
    "        # x ->      (batch, T, d_model)\n",
    "        K = batched_matmul(x, self.W_K)\n",
    "        Q = batched_matmul(x, self.W_Q)\n",
    "        V = batched_matmul(x, self.W_V)\n",
    "\n",
    "        # (batch, T, d_model) x (batch, d_model, d_k) -> (batch, T, d_k)\n",
    "        result = torch.bmm(Q, K.transpose(1, 2)) / (K.shape[-1] ** 0.5)\n",
    "        if self.mask:\n",
    "            result = batched_matmul(result, self.mask)\n",
    "        result = F.softmax(result, dim=-1)\n",
    "        result = torch.bmm(result, V)\n",
    "        return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([128, 16])\n",
      "torch.Size([128, 16])\n",
      "torch.Size([128, 16])\n",
      "torch.Size([128, 80, 16])\n"
     ]
    }
   ],
   "source": [
    "att = Attention(T=T, d_K=D_K, d_V=D_V, d_model=D_MODEL)\n",
    "x = torch.normal(mean=0, std=0.01, size=(BATCH_SIZE, T, D_MODEL))\n",
    "\n",
    "att_result = att.forward(x)\n",
    "assert att_result.shape == (BATCH_SIZE, T, D_V)\n",
    "print(att.W_K.shape)\n",
    "print(att.W_Q.shape)\n",
    "print(att.W_V.shape)\n",
    "print(att_result.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Multi-Head Attention"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MultiHeadAttention(nn.Module):\n",
    "    def __init__(\n",
    "        self, h: int, T=T, d_K=D_K, d_V=D_V, d_model=D_MODEL, *args, **kwargs\n",
    "    ) -> None:\n",
    "        super().__init__(*args, **kwargs)\n",
    "        self.h = h\n",
    "        self.attentions = nn.ModuleList(\n",
    "            [Attention(T=T, d_K=d_K, d_model=d_model, d_V=d_V) for _ in range(h)]\n",
    "        )\n",
    "        self.W_O = torch.normal(0, 0.1, size=(h * d_V, d_model), requires_grad=True)\n",
    "        self.T = T\n",
    "        self.d_V = d_V\n",
    "\n",
    "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
    "        attention_results = []\n",
    "        \n",
    "        for attention in self.attentions:\n",
    "            attention_result = attention(x)\n",
    "            attention_results.append(attention_result)\n",
    "\n",
    "        concatenated = torch.concat(attention_results, dim=-1)\n",
    "        return batched_matmul(concatenated, self.W_O)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "mha = MultiHeadAttention(h=H, T=T, d_K=D_K, d_V=D_V, d_model=D_MODEL)\n",
    "assert mha(x).shape == (BATCH_SIZE, T, D_MODEL)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. The transformer block"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([128, 80, 128])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class TransformerBlock(nn.Module):\n",
    "    def __init__(\n",
    "        self, T=T, d_K=D_K, d_V=D_V, d_model=D_MODEL, h=H, dropout=0.1, *args, **kwargs\n",
    "    ) -> None:\n",
    "        super().__init__(*args, **kwargs)\n",
    "        self.mha = MultiHeadAttention(h, T=T, d_K=d_K, d_V=d_V, d_model=d_model)\n",
    "        self.layer_norm = nn.LayerNorm(d_model)\n",
    "        self.ann = nn.Sequential(\n",
    "            nn.Linear(d_model, d_model),\n",
    "            nn.Softmax(dim=-1),\n",
    "        )\n",
    "    \n",
    "    def forward(self, x: torch.Tensor):\n",
    "        x = self.layer_norm(x + self.mha(x))\n",
    "        x = self.layer_norm(x + self.ann(x))\n",
    "        return x\n",
    "        \n",
    "transformerBlock = TransformerBlock()\n",
    "transformerBlock(x).shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. The positional encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([80, 128])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def PositionalEncoding(T: int, d_model) -> torch.Tensor:\n",
    "    encodings = torch.zeros(size=(T, d_model), requires_grad=False)\n",
    "    counter = 0\n",
    "    for pos in range(T):\n",
    "        for i in range((d_model // 2) + 1):\n",
    "            if 2 * i < d_model:\n",
    "                counter += 1\n",
    "                encodings[pos, 2 * i] = torch.sin(\n",
    "                    pos / torch.tensor(10000).pow(2 * i / d_model)\n",
    "                )\n",
    "            if 2 * i + 1 < d_model:\n",
    "                counter += 1\n",
    "                encodings[pos, 2 * i + 1] = torch.cos(\n",
    "                    pos / torch.tensor(10000).pow(2 * i / d_model)\n",
    "                )\n",
    "    assert counter == T * d_model\n",
    "    return encodings\n",
    "\n",
    "\n",
    "PositionalEncoding(T, D_MODEL).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_80185/2721896283.py:1: UserWarning: torch.range is deprecated and will be removed in a future release because its behavior is inconsistent with Python's range builtin. Instead, use torch.arange, which produces values in [start, end).\n",
      "  torch.range(0, 10).reshape(-1, 1)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.],\n",
       "        [ 1.],\n",
       "        [ 2.],\n",
       "        [ 3.],\n",
       "        [ 4.],\n",
       "        [ 5.],\n",
       "        [ 6.],\n",
       "        [ 7.],\n",
       "        [ 8.],\n",
       "        [ 9.],\n",
       "        [10.]])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.range(0, 10).reshape(-1, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# class Embedding(nn.Module):\n",
    "#     def __init__(self, vocab_size: int, d_model: int, *args, **kwargs) -> None:\n",
    "#         super().__init__(*args, **kwargs)\n",
    "#         self.vocab_size = vocab_size\n",
    "#         self.embedding = torch.normal(\n",
    "#             mean=0.0, std=0.1, size=(vocab_size, d_model), requires_grad=True\n",
    "#         )\n",
    "\n",
    "#     # TODO: make work in batches\n",
    "#     def forward(self, x_one_hot: torch.Tensor):\n",
    "#         # print(x_one_hot.shape)\n",
    "#         batched_range = torch.arange(self.vocab_size).type(torch.float32)\n",
    "#         batched_range = batched_range.unsqueeze(0).repeat(x_one_hot.shape[1], 1)\n",
    "#         # print(batched_range.shape)\n",
    "#         positions = batched_matmul(x_one_hot, batched_range.transpose(1, 0)).type(torch.int64)\n",
    "\n",
    "#         print(positions)\n",
    "#         print(self.embedding.shape)\n",
    "#         # print(self.embedding)\n",
    "#         return self.embedding[positions]\n",
    "\n",
    "\n",
    "# emb = Embedding(3, 2)\n",
    "# emb.forward(\n",
    "#     torch.FloatTensor(\n",
    "#         [\n",
    "#             [[0, 1, 0], [0, 0, 1], [1, 0, 0], [0, 0, 1]],\n",
    "#             [[1, 0, 0], [0, 1, 0], [1, 0, 0], [0, 1, 0]],\n",
    "#         ]\n",
    "#     )\n",
    "# )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. The embedding layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This Embedding class was designed for one hot encoded inputs\n",
    "# But this won't be the case. Inputs will be integers.\n",
    "# So we won't use this\n",
    "# \n",
    "# \n",
    "# class Embedding(nn.Module):\n",
    "#     def __init__(self, vocab_size: int, d_model: int, *args, **kwargs) -> None:\n",
    "#         super().__init__(*args, **kwargs)\n",
    "#         self.vocab_size = vocab_size\n",
    "#         self.embedding = torch.normal(\n",
    "#             mean=0.0, std=0.1, size=(vocab_size, d_model), requires_grad=True\n",
    "#         )\n",
    "\n",
    "#     def forward(self, x_one_hot: torch.Tensor):\n",
    "#         positions = torch.matmul(\n",
    "#             x_one_hot, torch.arange(self.vocab_size, dtype=torch.float32)\n",
    "#         ).type(torch.int64)\n",
    "\n",
    "#         # print(positions)\n",
    "#         # print(self.embedding)\n",
    "#         return self.embedding[positions]\n",
    "\n",
    "\n",
    "# emb = Embedding(vocab_size=3, d_model=2)\n",
    "# emb.forward(\n",
    "#     torch.FloatTensor(\n",
    "#         [\n",
    "#             [[0, 1, 0], [0, 0, 1], [1, 0, 0], [0, 0, 1]],\n",
    "#             [[1, 0, 0], [0, 1, 0], [1, 0, 0], [0, 1, 0]],\n",
    "#         ]\n",
    "#     )\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[-0.0224,  0.0867],\n",
       "         [-0.0946,  0.0004]],\n",
       "\n",
       "        [[-0.0946,  0.0004],\n",
       "         [-0.0379,  0.2879]]], grad_fn=<IndexBackward0>)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class Embedding(nn.Module):\n",
    "    def __init__(self, vocab_size, d_model, padding_idx=0):\n",
    "        super(Embedding, self).__init__()\n",
    "        self.embedding = torch.normal(\n",
    "            mean=0.0, std=0.1, size=(vocab_size, d_model), requires_grad=True\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.embedding[x.int()]\n",
    "\n",
    "\n",
    "emb = Embedding(vocab_size=3, d_model=2)\n",
    "emb.forward(torch.FloatTensor([[2, 1], [1, 0]]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. The Classification Encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ClassifierEncoder(nn.Module):\n",
    "    def __init__(\n",
    "        self,\n",
    "        T=T,\n",
    "        d_K=D_K,\n",
    "        d_V=D_V,\n",
    "        d_model=D_MODEL,\n",
    "        h=H,\n",
    "        vocab_size=VOCAB_SIZE,\n",
    "        n_classes=N_CLASSES,\n",
    "        dropout=0.1,\n",
    "        *args,\n",
    "        **kwargs\n",
    "    ):\n",
    "        super(ClassifierEncoder, self).__init__()\n",
    "        self.T = T\n",
    "        self.d_K = d_K\n",
    "\n",
    "        self.embedding = nn.Embedding(vocab_size, d_model)\n",
    "        self.position_encoding: torch.Tensor = PositionalEncoding(T, d_model)\n",
    "\n",
    "        self.transformer_blocks = nn.ModuleList()\n",
    "        for _ in range(N_MHA_BLOCKS_ENCODER):\n",
    "            self.transformer_blocks.append(\n",
    "                TransformerBlock(T=T, d_K=d_K, d_V=d_V, d_model=d_model, h=h)\n",
    "            )\n",
    "\n",
    "        self.prediction_head = nn.Linear(d_model, n_classes)\n",
    "\n",
    "    def forward(self, x: torch.Tensor):\n",
    "        positionalEncoding = self.position_encoding.repeat(x.shape[0], 1, 1)\n",
    "\n",
    "        x = positionalEncoding + self.embedding(x)\n",
    "\n",
    "        for block in self.transformer_blocks:\n",
    "            x = block(x)\n",
    "\n",
    "        x = self.prediction_head(x)\n",
    "\n",
    "        x = x[:, -1, :]\n",
    "\n",
    "        x = F.softmax(x, dim=-1)\n",
    "        # Select the last value along the T dimension\n",
    "        # Because classification is only obtained at the end of the sequence\n",
    "\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Let's try a classification problem using the CLassification Encoder\n",
    "\n",
    "* See the file: Fine-Tuning (Intermediate)/Fine-Tunning Sentiment Custom Dataset + Labels.ipynb"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## First, lets make a dataset with cross validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweet_id</th>\n",
       "      <th>airline_sentiment</th>\n",
       "      <th>airline_sentiment_confidence</th>\n",
       "      <th>negativereason</th>\n",
       "      <th>negativereason_confidence</th>\n",
       "      <th>airline</th>\n",
       "      <th>airline_sentiment_gold</th>\n",
       "      <th>name</th>\n",
       "      <th>negativereason_gold</th>\n",
       "      <th>retweet_count</th>\n",
       "      <th>text</th>\n",
       "      <th>tweet_coord</th>\n",
       "      <th>tweet_created</th>\n",
       "      <th>tweet_location</th>\n",
       "      <th>user_timezone</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>570306133677760513</td>\n",
       "      <td>neutral</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Virgin America</td>\n",
       "      <td>NaN</td>\n",
       "      <td>cairdin</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>@VirginAmerica What @dhepburn said.</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2015-02-24 11:35:52 -0800</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Eastern Time (US &amp; Canada)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>570301130888122368</td>\n",
       "      <td>positive</td>\n",
       "      <td>0.3486</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>Virgin America</td>\n",
       "      <td>NaN</td>\n",
       "      <td>jnardino</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>@VirginAmerica plus you've added commercials t...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2015-02-24 11:15:59 -0800</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Pacific Time (US &amp; Canada)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>570301083672813571</td>\n",
       "      <td>neutral</td>\n",
       "      <td>0.6837</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Virgin America</td>\n",
       "      <td>NaN</td>\n",
       "      <td>yvonnalynn</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>@VirginAmerica I didn't today... Must mean I n...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2015-02-24 11:15:48 -0800</td>\n",
       "      <td>Lets Play</td>\n",
       "      <td>Central Time (US &amp; Canada)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>570301031407624196</td>\n",
       "      <td>negative</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>Bad Flight</td>\n",
       "      <td>0.7033</td>\n",
       "      <td>Virgin America</td>\n",
       "      <td>NaN</td>\n",
       "      <td>jnardino</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>@VirginAmerica it's really aggressive to blast...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2015-02-24 11:15:36 -0800</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Pacific Time (US &amp; Canada)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>570300817074462722</td>\n",
       "      <td>negative</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>Can't Tell</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>Virgin America</td>\n",
       "      <td>NaN</td>\n",
       "      <td>jnardino</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>@VirginAmerica and it's a really big bad thing...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2015-02-24 11:14:45 -0800</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Pacific Time (US &amp; Canada)</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             tweet_id airline_sentiment  airline_sentiment_confidence  \\\n",
       "0  570306133677760513           neutral                        1.0000   \n",
       "1  570301130888122368          positive                        0.3486   \n",
       "2  570301083672813571           neutral                        0.6837   \n",
       "3  570301031407624196          negative                        1.0000   \n",
       "4  570300817074462722          negative                        1.0000   \n",
       "\n",
       "  negativereason  negativereason_confidence         airline  \\\n",
       "0            NaN                        NaN  Virgin America   \n",
       "1            NaN                     0.0000  Virgin America   \n",
       "2            NaN                        NaN  Virgin America   \n",
       "3     Bad Flight                     0.7033  Virgin America   \n",
       "4     Can't Tell                     1.0000  Virgin America   \n",
       "\n",
       "  airline_sentiment_gold        name negativereason_gold  retweet_count  \\\n",
       "0                    NaN     cairdin                 NaN              0   \n",
       "1                    NaN    jnardino                 NaN              0   \n",
       "2                    NaN  yvonnalynn                 NaN              0   \n",
       "3                    NaN    jnardino                 NaN              0   \n",
       "4                    NaN    jnardino                 NaN              0   \n",
       "\n",
       "                                                text tweet_coord  \\\n",
       "0                @VirginAmerica What @dhepburn said.         NaN   \n",
       "1  @VirginAmerica plus you've added commercials t...         NaN   \n",
       "2  @VirginAmerica I didn't today... Must mean I n...         NaN   \n",
       "3  @VirginAmerica it's really aggressive to blast...         NaN   \n",
       "4  @VirginAmerica and it's a really big bad thing...         NaN   \n",
       "\n",
       "               tweet_created tweet_location               user_timezone  \n",
       "0  2015-02-24 11:35:52 -0800            NaN  Eastern Time (US & Canada)  \n",
       "1  2015-02-24 11:15:59 -0800            NaN  Pacific Time (US & Canada)  \n",
       "2  2015-02-24 11:15:48 -0800      Lets Play  Central Time (US & Canada)  \n",
       "3  2015-02-24 11:15:36 -0800            NaN  Pacific Time (US & Canada)  \n",
       "4  2015-02-24 11:14:45 -0800            NaN  Pacific Time (US & Canada)  "
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_ = pd.read_csv(\"../Fine-Tuning (Intermediate)/AirlineTweets.csv\")\n",
    "df_.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>airline_sentiment</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>neutral</td>\n",
       "      <td>@VirginAmerica What @dhepburn said.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>positive</td>\n",
       "      <td>@VirginAmerica plus you've added commercials t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>neutral</td>\n",
       "      <td>@VirginAmerica I didn't today... Must mean I n...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>negative</td>\n",
       "      <td>@VirginAmerica it's really aggressive to blast...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>negative</td>\n",
       "      <td>@VirginAmerica and it's a really big bad thing...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  airline_sentiment                                               text\n",
       "0           neutral                @VirginAmerica What @dhepburn said.\n",
       "1          positive  @VirginAmerica plus you've added commercials t...\n",
       "2           neutral  @VirginAmerica I didn't today... Must mean I n...\n",
       "3          negative  @VirginAmerica it's really aggressive to blast...\n",
       "4          negative  @VirginAmerica and it's a really big bad thing..."
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = df_[['airline_sentiment', 'text']].copy()\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>airline_sentiment</th>\n",
       "      <th>text</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>neutral</td>\n",
       "      <td>@VirginAmerica What @dhepburn said.</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>positive</td>\n",
       "      <td>@VirginAmerica plus you've added commercials t...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>neutral</td>\n",
       "      <td>@VirginAmerica I didn't today... Must mean I n...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>negative</td>\n",
       "      <td>@VirginAmerica it's really aggressive to blast...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>negative</td>\n",
       "      <td>@VirginAmerica and it's a really big bad thing...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  airline_sentiment                                               text  target\n",
       "0           neutral                @VirginAmerica What @dhepburn said.       2\n",
       "1          positive  @VirginAmerica plus you've added commercials t...       1\n",
       "2           neutral  @VirginAmerica I didn't today... Must mean I n...       2\n",
       "3          negative  @VirginAmerica it's really aggressive to blast...       0\n",
       "4          negative  @VirginAmerica and it's a really big bad thing...       0"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "target_map = {\n",
    "    'positive': 1,\n",
    "    'negative': 0,\n",
    "    'neutral': 2,\n",
    "}\n",
    "df['target'] = df['airline_sentiment'].map(target_map)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>airline_sentiment</th>\n",
       "      <th>text</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>positive</td>\n",
       "      <td>@VirginAmerica plus you've added commercials t...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>negative</td>\n",
       "      <td>@VirginAmerica it's really aggressive to blast...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>negative</td>\n",
       "      <td>@VirginAmerica and it's a really big bad thing...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>negative</td>\n",
       "      <td>@VirginAmerica seriously would pay $30 a fligh...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>positive</td>\n",
       "      <td>@VirginAmerica yes, nearly every time I fly VX...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  airline_sentiment                                               text  target\n",
       "1          positive  @VirginAmerica plus you've added commercials t...       1\n",
       "3          negative  @VirginAmerica it's really aggressive to blast...       0\n",
       "4          negative  @VirginAmerica and it's a really big bad thing...       0\n",
       "5          negative  @VirginAmerica seriously would pay $30 a fligh...       0\n",
       "6          positive  @VirginAmerica yes, nearly every time I fly VX...       1"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_filtered = df[df['target'] != 2]\n",
    "df_filtered.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sentence,label\n",
      "@VirginAmerica plus you've added commercials to the experience... tacky.,1\n",
      "\"@VirginAmerica it's really aggressive to blast obnoxious \"\"entertainment\"\" in your guests' faces &amp; they have little recourse\",0\n",
      "@VirginAmerica and it's a really big bad thing about it,0\n",
      "\"@VirginAmerica seriously would pay $30 a flight for seats that didn't have this playing.\n",
      "it's really the only bad thing about flying VA\",0\n",
      "\"@VirginAmerica yes, nearly every time I fly VX this “ear worm” won’t go away :)\",1\n",
      "\"@virginamerica Well, I didn't…but NOW I DO! :-D\",1\n",
      "\"@VirginAmerica it was amazing, and arrived an hour early. You're too good to me.\",1\n",
      "@VirginAmerica I &lt;3 pretty graphics. so much better than minimal iconography. :D,1\n"
     ]
    }
   ],
   "source": [
    "df2 = df_filtered[['text', 'target']]\n",
    "# Not documented info: targets must have the column name label\n",
    "# sentence may have other names, but not label\n",
    "df2.columns = ['sentence', 'label']\n",
    "df2.to_csv(\"data.csv\", index=False)\n",
    "!head data.csv\n",
    "# df2.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2045b7c20c7341a7b2370ae1e912bd88",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading data files:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d2c06d71611442c1a7fb7bf97f7a2955",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Extracting data files:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8fc883e7a060440dbd45245bc75be843",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating train split: 0 examples [00:00, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from datasets import load_dataset\n",
    "raw_dataset = load_dataset('csv', data_files=\"data.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['sentence', 'label'],\n",
       "        num_rows: 11541\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raw_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import Dataset, DatasetDict\n",
    "\n",
    "def splitTrainTestValidation(dataset: Dataset, valid_size=.1, test_size=.1):\n",
    "    len_valid = int(len(dataset) * valid_size)\n",
    "    len_test = int(len(dataset) * test_size)\n",
    "    \n",
    "    splited: DatasetDict = dataset.train_test_split(len_valid + len_test, shuffle=False, seed=42)\n",
    "    splited['validation'] = splited['test']\n",
    "    del splited['test']\n",
    "    \n",
    "    splited_2 = splited['validation'].train_test_split(len_test, shuffle=True, seed=42)\n",
    "    splited['validation'] = splited_2['train']\n",
    "    splited['test'] = splited_2['test']\n",
    "    \n",
    "    return splited"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split = raw_dataset['train'].train_test_split(test_size=.3, seed=42)\n",
    "split = splitTrainTestValidation(raw_dataset['train'], valid_size=.1, test_size=.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['sentence', 'label'],\n",
       "        num_rows: 9233\n",
       "    })\n",
       "    validation: Dataset({\n",
       "        features: ['sentence', 'label'],\n",
       "        num_rows: 1154\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['sentence', 'label'],\n",
       "        num_rows: 1154\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer\n",
    "\n",
    "checkpoint = \"distilbert-base-cased\"\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(checkpoint)\n",
    "\n",
    "\n",
    "def tokenize_fn(batch):\n",
    "    return tokenizer(batch[\"sentence\"], truncation=True, padding='max_length', max_length=T)\n",
    "\n",
    "\n",
    "# tokenizer(\"This is an example\", truncation=True, padding=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "29c114be7fd449b7b4195b8e1f00c54d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/9233 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3a02530b2db146719ada3ce782a78a2d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/1154 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "34b2edc702604d69814db58c2d5b4d4e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/1154 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['sentence', 'label', 'input_ids', 'attention_mask'],\n",
       "        num_rows: 9233\n",
       "    })\n",
       "    validation: Dataset({\n",
       "        features: ['sentence', 'label', 'input_ids', 'attention_mask'],\n",
       "        num_rows: 1154\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['sentence', 'label', 'input_ids', 'attention_mask'],\n",
       "        num_rows: 1154\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "tokenized_datasets = split.map(tokenize_fn, batched=False)\n",
    "tokenized_datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bdf54786560e4179854c9b1a42cd4db4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Filter:   0%|          | 0/1154 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8c464826db2c43c28b13c962b4017067",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Filter:   0%|          | 0/1154 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['sentence', 'label', 'input_ids', 'attention_mask'],\n",
       "        num_rows: 9233\n",
       "    })\n",
       "    validation: Dataset({\n",
       "        features: ['sentence', 'label', 'input_ids', 'attention_mask'],\n",
       "        num_rows: 853\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['sentence', 'label', 'input_ids', 'attention_mask'],\n",
       "        num_rows: 844\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Little notation here:\n",
    "# token is an int from the tokenizer\n",
    "# idx is our index, to use in our embedding\n",
    "\n",
    "token2idx = {0: 0}\n",
    "idx2token = {}\n",
    "\n",
    "all_tokens = [\n",
    "    element\n",
    "    for list_ids in tokenized_datasets[\"train\"][\"input_ids\"]\n",
    "    for element in list_ids\n",
    "]\n",
    "all_tokens = list(set(all_tokens))\n",
    "\n",
    "token_index = 0\n",
    "for token in all_tokens:\n",
    "    if token not in token2idx:\n",
    "        token2idx[token] = token_index\n",
    "        idx2token[token_index] = token\n",
    "        token_index += 1\n",
    "\n",
    "\n",
    "def filterSplit(splited_dataset):\n",
    "    \"\"\"For valid and test datasets, get only those which all inpu_ids is in splited_dataset['train']\"\"\"\n",
    "\n",
    "    for split in [\"validation\", \"test\"]:\n",
    "        # Filter the splited_dataset[split] to only keep the ids which are in splited_dataset['train']\n",
    "        splited_dataset[split] = splited_dataset[split].filter(\n",
    "            lambda x: all(token in token2idx for token in x[\"input_ids\"])\n",
    "        )\n",
    "\n",
    "    return splited_dataset\n",
    "\n",
    "\n",
    "filtered_datasets = filterSplit(tokenized_datasets)\n",
    "filtered_datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vamos construir nosso dicionário de tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ed1ad1d717c4407c83db5a32de5aa689",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/9233 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f9d39b9f5d294adc844f3046c751a4c0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/853 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8f00f7b23ea0463291bb5b098413c053",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/844 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['sentence', 'label', 'input_ids', 'attention_mask', 'input_idx'],\n",
       "        num_rows: 9233\n",
       "    })\n",
       "    validation: Dataset({\n",
       "        features: ['sentence', 'label', 'input_ids', 'attention_mask', 'input_idx'],\n",
       "        num_rows: 853\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['sentence', 'label', 'input_ids', 'attention_mask', 'input_idx'],\n",
       "        num_rows: 844\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def makeIndex(batch):\n",
    "    batch[\"input_idx\"] = [token2idx[single] for single in batch[\"input_ids\"]]\n",
    "    return batch\n",
    "\n",
    "data = filtered_datasets.map(makeIndex, batched=False)\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[80]"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Assert all same length\n",
    "list(set([len(l_idx) for l_idx in data['train']['input_idx']]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([9233, 80])"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_train = torch.Tensor(data['train']['input_idx']).type(torch.int32)\n",
    "data_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0., 1.],\n",
       "        [1., 0.],\n",
       "        [1., 0.],\n",
       "        [1., 0.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.]])"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch.nn.functional as F\n",
    "target_train = torch.Tensor(data['train']['label'])\n",
    "\n",
    "#make one_hot\n",
    "target_train = F.one_hot(target_train.to(torch.int64), num_classes=N_CLASSES).float()\n",
    "\n",
    "target_train[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([853, 80])"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_valid = torch.Tensor(data['validation']['input_idx']).type(torch.int32)\n",
    "data_valid.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1., 0.],\n",
       "        [1., 0.],\n",
       "        [1., 0.],\n",
       "        [1., 0.],\n",
       "        [1., 0.],\n",
       "        [1., 0.],\n",
       "        [1., 0.],\n",
       "        [1., 0.],\n",
       "        [0., 1.],\n",
       "        [1., 0.]])"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "target_valid = torch.Tensor(data['validation']['label'])\n",
    "\n",
    "#make one_hot\n",
    "target_valid = F.one_hot(target_valid.to(torch.int64), num_classes=N_CLASSES).float()\n",
    "\n",
    "target_valid[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([844, 80])"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_test = torch.Tensor(data['test']['input_idx']).type(torch.int32)\n",
    "data_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1., 0.],\n",
       "        [1., 0.],\n",
       "        [1., 0.],\n",
       "        [1., 0.],\n",
       "        [1., 0.],\n",
       "        [1., 0.],\n",
       "        [0., 1.],\n",
       "        [1., 0.],\n",
       "        [1., 0.],\n",
       "        [1., 0.]])"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "target_test = torch.Tensor(data['test']['label'])\n",
    "\n",
    "#make one_hot\n",
    "target_test = F.one_hot(target_test.to(torch.int64), num_classes=N_CLASSES).float()\n",
    "\n",
    "target_test[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Now let's train our model! "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:  1\n",
      "Train Epoch: 1 [0/9233 (0%)]\tLoss: 0.006452\n",
      "Train Epoch: 1 [1280/9233 (14%)]\tLoss: 0.004419\n",
      "Train Epoch: 1 [2560/9233 (27%)]\tLoss: 0.005035\n",
      "Train Epoch: 1 [3840/9233 (41%)]\tLoss: 0.004015\n",
      "Train Epoch: 1 [5120/9233 (55%)]\tLoss: 0.003774\n",
      "Train Epoch: 1 [6400/9233 (68%)]\tLoss: 0.004556\n",
      "Train Epoch: 1 [7680/9233 (82%)]\tLoss: 0.004318\n",
      "Train Epoch: 1 [8960/9233 (96%)]\tLoss: 0.003249\n",
      "\n",
      "Test set: Average loss: 0.003595, Accuracy: 7460/9233 (80.80%)\n",
      "\n",
      "Epoch:  2\n",
      "Train Epoch: 2 [0/9233 (0%)]\tLoss: 0.003904\n",
      "Train Epoch: 2 [1280/9233 (14%)]\tLoss: 0.003975\n",
      "Train Epoch: 2 [2560/9233 (27%)]\tLoss: 0.002636\n",
      "Train Epoch: 2 [3840/9233 (41%)]\tLoss: 0.003239\n",
      "Train Epoch: 2 [5120/9233 (55%)]\tLoss: 0.002014\n",
      "Train Epoch: 2 [6400/9233 (68%)]\tLoss: 0.002228\n",
      "Train Epoch: 2 [7680/9233 (82%)]\tLoss: 0.002861\n",
      "Train Epoch: 2 [8960/9233 (96%)]\tLoss: 0.001878\n",
      "\n",
      "Test set: Average loss: 0.002325, Accuracy: 7838/9233 (84.89%)\n",
      "\n",
      "Epoch:  3\n",
      "Train Epoch: 3 [0/9233 (0%)]\tLoss: 0.002280\n",
      "Train Epoch: 3 [1280/9233 (14%)]\tLoss: 0.002985\n",
      "Train Epoch: 3 [2560/9233 (27%)]\tLoss: 0.000940\n",
      "Train Epoch: 3 [3840/9233 (41%)]\tLoss: 0.000919\n",
      "Train Epoch: 3 [5120/9233 (55%)]\tLoss: 0.001382\n",
      "Train Epoch: 3 [6400/9233 (68%)]\tLoss: 0.001928\n",
      "Train Epoch: 3 [7680/9233 (82%)]\tLoss: 0.000981\n",
      "Train Epoch: 3 [8960/9233 (96%)]\tLoss: 0.002560\n",
      "\n",
      "Test set: Average loss: 0.001486, Accuracy: 8553/9233 (92.64%)\n",
      "\n",
      "Epoch:  4\n",
      "Train Epoch: 4 [0/9233 (0%)]\tLoss: 0.001519\n",
      "Train Epoch: 4 [1280/9233 (14%)]\tLoss: 0.001020\n",
      "Train Epoch: 4 [2560/9233 (27%)]\tLoss: 0.000845\n",
      "Train Epoch: 4 [3840/9233 (41%)]\tLoss: 0.001296\n",
      "Train Epoch: 4 [5120/9233 (55%)]\tLoss: 0.001614\n",
      "Train Epoch: 4 [6400/9233 (68%)]\tLoss: 0.001309\n",
      "Train Epoch: 4 [7680/9233 (82%)]\tLoss: 0.000957\n",
      "Train Epoch: 4 [8960/9233 (96%)]\tLoss: 0.000927\n",
      "\n",
      "Test set: Average loss: 0.000806, Accuracy: 8877/9233 (96.14%)\n",
      "\n",
      "Epoch:  5\n",
      "Train Epoch: 5 [0/9233 (0%)]\tLoss: 0.000753\n",
      "Train Epoch: 5 [1280/9233 (14%)]\tLoss: 0.000553\n",
      "Train Epoch: 5 [2560/9233 (27%)]\tLoss: 0.001363\n",
      "Train Epoch: 5 [3840/9233 (41%)]\tLoss: 0.000612\n",
      "Train Epoch: 5 [5120/9233 (55%)]\tLoss: 0.000358\n",
      "Train Epoch: 5 [6400/9233 (68%)]\tLoss: 0.001542\n",
      "Train Epoch: 5 [7680/9233 (82%)]\tLoss: 0.001238\n",
      "Train Epoch: 5 [8960/9233 (96%)]\tLoss: 0.001078\n",
      "\n",
      "Test set: Average loss: 0.001159, Accuracy: 8601/9233 (93.15%)\n",
      "\n",
      "Epoch:  6\n",
      "Train Epoch: 6 [0/9233 (0%)]\tLoss: 0.001235\n",
      "Train Epoch: 6 [1280/9233 (14%)]\tLoss: 0.000416\n",
      "Train Epoch: 6 [2560/9233 (27%)]\tLoss: 0.000292\n",
      "Train Epoch: 6 [3840/9233 (41%)]\tLoss: 0.000370\n",
      "Train Epoch: 6 [5120/9233 (55%)]\tLoss: 0.000447\n",
      "Train Epoch: 6 [6400/9233 (68%)]\tLoss: 0.000325\n",
      "Train Epoch: 6 [7680/9233 (82%)]\tLoss: 0.000557\n",
      "Train Epoch: 6 [8960/9233 (96%)]\tLoss: 0.000572\n",
      "\n",
      "Test set: Average loss: 0.000296, Accuracy: 9104/9233 (98.60%)\n",
      "\n",
      "Epoch:  7\n",
      "Train Epoch: 7 [0/9233 (0%)]\tLoss: 0.000195\n",
      "Train Epoch: 7 [1280/9233 (14%)]\tLoss: 0.000180\n",
      "Train Epoch: 7 [2560/9233 (27%)]\tLoss: 0.000110\n",
      "Train Epoch: 7 [3840/9233 (41%)]\tLoss: 0.000528\n",
      "Train Epoch: 7 [5120/9233 (55%)]\tLoss: 0.000577\n",
      "Train Epoch: 7 [6400/9233 (68%)]\tLoss: 0.000662\n",
      "Train Epoch: 7 [7680/9233 (82%)]\tLoss: 0.001238\n",
      "Train Epoch: 7 [8960/9233 (96%)]\tLoss: 0.000285\n",
      "\n",
      "Test set: Average loss: 0.000490, Accuracy: 9006/9233 (97.54%)\n",
      "\n",
      "Epoch:  8\n",
      "Train Epoch: 8 [0/9233 (0%)]\tLoss: 0.000494\n",
      "Train Epoch: 8 [1280/9233 (14%)]\tLoss: 0.000289\n",
      "Train Epoch: 8 [2560/9233 (27%)]\tLoss: 0.000159\n",
      "Train Epoch: 8 [3840/9233 (41%)]\tLoss: 0.000058\n",
      "Train Epoch: 8 [5120/9233 (55%)]\tLoss: 0.000167\n",
      "Train Epoch: 8 [6400/9233 (68%)]\tLoss: 0.000248\n",
      "Train Epoch: 8 [7680/9233 (82%)]\tLoss: 0.000156\n",
      "Train Epoch: 8 [8960/9233 (96%)]\tLoss: 0.000273\n",
      "\n",
      "Test set: Average loss: 0.000236, Accuracy: 9168/9233 (99.30%)\n",
      "\n",
      "Epoch:  9\n",
      "Train Epoch: 9 [0/9233 (0%)]\tLoss: 0.000179\n",
      "Train Epoch: 9 [1280/9233 (14%)]\tLoss: 0.000326\n",
      "Train Epoch: 9 [2560/9233 (27%)]\tLoss: 0.000765\n",
      "Train Epoch: 9 [3840/9233 (41%)]\tLoss: 0.000086\n",
      "Train Epoch: 9 [5120/9233 (55%)]\tLoss: 0.001441\n",
      "Train Epoch: 9 [6400/9233 (68%)]\tLoss: 0.000185\n",
      "Train Epoch: 9 [7680/9233 (82%)]\tLoss: 0.000087\n",
      "Train Epoch: 9 [8960/9233 (96%)]\tLoss: 0.000407\n",
      "\n",
      "Test set: Average loss: 0.000534, Accuracy: 8983/9233 (97.29%)\n",
      "\n",
      "Epoch:  10\n",
      "Train Epoch: 10 [0/9233 (0%)]\tLoss: 0.000825\n",
      "Train Epoch: 10 [1280/9233 (14%)]\tLoss: 0.000153\n",
      "Train Epoch: 10 [2560/9233 (27%)]\tLoss: 0.000245\n",
      "Train Epoch: 10 [3840/9233 (41%)]\tLoss: 0.000192\n",
      "Train Epoch: 10 [5120/9233 (55%)]\tLoss: 0.000260\n",
      "Train Epoch: 10 [6400/9233 (68%)]\tLoss: 0.000435\n",
      "Train Epoch: 10 [7680/9233 (82%)]\tLoss: 0.000516\n",
      "Train Epoch: 10 [8960/9233 (96%)]\tLoss: 0.000302\n",
      "\n",
      "Test set: Average loss: 0.000279, Accuracy: 9101/9233 (98.57%)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "log_interval = 10\n",
    "EPOCHS = 10\n",
    "\n",
    "\n",
    "def train(model, train_loader, optimizer, criterion, epoch):\n",
    "    model = model.to(device)\n",
    "    model.train()\n",
    "    for batch_idx, (data, target) in enumerate(train_loader):\n",
    "        data, target = data.to(device), target.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        output = model(data)\n",
    "        loss = criterion(output, target)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        if batch_idx % log_interval == 0:\n",
    "            print(\n",
    "                \"Train Epoch: {} [{}/{} ({:.0f}%)]\\tLoss: {:.6f}\".format(\n",
    "                    epoch,\n",
    "                    batch_idx * len(data),\n",
    "                    len(train_loader.dataset),\n",
    "                    100.0 * batch_idx / len(train_loader),\n",
    "                    loss.item() / len(data),\n",
    "                )\n",
    "            )\n",
    "\n",
    "\n",
    "def evaluate(model, test_loader, criterion):\n",
    "    model = model.to(device)\n",
    "    model.eval()\n",
    "    test_loss = 0.0\n",
    "    correct = 0\n",
    "    with torch.no_grad():\n",
    "        for data, target in test_loader:\n",
    "            data, target = data.to(device), target.to(device)\n",
    "            output = model(data)\n",
    "            test_loss += criterion(output, target).item()\n",
    "            pred = output.argmax(dim=1, keepdim=True)\n",
    "            target_ = target.argmax(dim=1, keepdim=True)\n",
    "            correct += pred.eq(target_).sum()\n",
    "\n",
    "    test_loss /= len(test_loader.dataset)\n",
    "    print(\n",
    "        \"\\nTest set: Average loss: {:.6f}, Accuracy: {}/{} ({:.2f}%)\\n\".format(\n",
    "            test_loss,\n",
    "            correct,\n",
    "            len(test_loader.dataset),\n",
    "            correct / len(test_loader.dataset) * 100,\n",
    "        )\n",
    "    )\n",
    "\n",
    "\n",
    "class MyDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, data, target):\n",
    "        self.data = data\n",
    "        self.target = target\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.data[idx], self.target[idx]\n",
    "\n",
    "\n",
    "model = ClassifierEncoder(vocab_size=len(token2idx))\n",
    "\n",
    "train_dataset = MyDataset(data_train, target_train)\n",
    "train_loader = torch.utils.data.DataLoader(\n",
    "    train_dataset, batch_size=BATCH_SIZE, shuffle=True\n",
    ")\n",
    "\n",
    "test_dataset = MyDataset(data_train, target_train)\n",
    "test_loader = torch.utils.data.DataLoader(test_dataset, batch_size=BATCH_SIZE)\n",
    "\n",
    "# TODO: get optimizer and criterion from literature\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.01)\n",
    "criterion = torch.nn.BCELoss()\n",
    "\n",
    "for epoch in range(1, EPOCHS + 1):\n",
    "    print(\"Epoch: \", epoch)\n",
    "    train(model, train_loader, optimizer, criterion, epoch)\n",
    "    # TODO: investigate very high accuracy! Why?\n",
    "    evaluate(model, test_loader, criterion)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "gpt",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
