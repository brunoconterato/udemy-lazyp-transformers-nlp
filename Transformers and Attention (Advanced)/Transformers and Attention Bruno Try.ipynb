{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Let's build the transformer's encoder\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.0. Init\n",
    "\n",
    "* Initialize the notebook environment.\n",
    "* Hyperparameters definition\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "from datasets import Dataset, DatasetDict, load_dataset\n",
    "from transformers import AutoTokenizer\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import math\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import unittest\n",
    "\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hyperparameters Here\n",
    "BATCH_SIZE = 128\n",
    "T = 80  # sentence length\n",
    "D_K = 16\n",
    "D_V = 16\n",
    "D_MODEL = 128\n",
    "H = 8\n",
    "VOCAB_SIZE = 10\n",
    "N_TRANSFORMERS_BLOCKS_ENCODER = 6\n",
    "N_CLASSES = 2  # classes of classifier\n",
    "\n",
    "USE_CAUSAL_MASK = True\n",
    "\n",
    "LOG_INTERVAL_IN_BATCHES = 10\n",
    "EPOCHS = 12\n",
    "\n",
    "ALLOW_GPU = True\n",
    "\n",
    "RUN_UNIT_TESTS = True\n",
    "TRAIN_MODEL = True\n",
    "\n",
    "SEED = 42"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cuda device\n",
      "Using manual seed: 42\n"
     ]
    }
   ],
   "source": [
    "# Set device\n",
    "device = \"cuda\" if torch.cuda.is_available() and ALLOW_GPU else \"cpu\"\n",
    "print(\"Using {} device\".format(device))\n",
    "\n",
    "\n",
    "# Set seeds to reprodutivity\n",
    "torch.manual_seed(SEED)\n",
    "np.random.seed(SEED)\n",
    "print(f\"Using manual seed: {SEED}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.1. Attention\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.0900, 0.2447, 0.6652],\n",
      "        [0.0900, 0.2447, 0.6652]])\n"
     ]
    }
   ],
   "source": [
    "# Test softmax x axis:\n",
    "matrix = torch.tensor([[1.0, 2.0, 3.0], [4.0, 5.0, 6.0]])\n",
    "\n",
    "softmaxed_matrix = F.softmax(matrix, dim=1)\n",
    "\n",
    "print(softmaxed_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def repeat(x: torch.Tensor, n: int):\n",
    "    # make shape (n, 1, 1, ...) --> quantity of 1's must be len(x.shape)\n",
    "    # for example, if shape of x is (3, 4, 8), shapee must be (n, 1, 1, 1)\n",
    "    tuple_ones = tuple(\n",
    "        (torch.tensor(x.shape) / torch.tensor(x.shape)).numpy().astype(int)\n",
    "    )\n",
    "    return x.unsqueeze(0).repeat((n, *tuple_ones))\n",
    "\n",
    "\n",
    "def batched_matmul(tensor_3d, tensor_2d):\n",
    "    W_repeated = repeat(tensor_2d, n=tensor_3d.shape[0])\n",
    "\n",
    "    return torch.bmm(tensor_3d, W_repeated)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Attention(nn.Module):\n",
    "    \"\"\"Convention from: https://www.udemy.com/course/data-science-transformers-nlp/learn/lecture/32255056#overview\n",
    "    In our convention, K, Q and V are learneable, different from the \"Attention is all you need\" paper.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, d_K, d_V, d_model: int, *args, **kwargs) -> None:\n",
    "        super().__init__(*args, **kwargs)\n",
    "\n",
    "        # Define trainable parameters with requires_grad=True\n",
    "        # torch 2d tensor initialized normally\n",
    "        self.W_K = nn.Parameter(torch.normal(mean=0, std=0.01, size=(d_model, d_K)))\n",
    "        self.W_Q = nn.Parameter(torch.normal(mean=0, std=0.01, size=(d_model, d_K)))\n",
    "        self.W_V = nn.Parameter(torch.normal(mean=0, std=0.01, size=(d_model, d_V)))\n",
    "\n",
    "        self.register_buffer(\n",
    "            \"causal_mask\", torch.tril(torch.ones((1, T, T))), persistent=False\n",
    "        )\n",
    "\n",
    "    def forward(self, x: torch.Tensor, pad_mask=None) -> torch.Tensor:\n",
    "        \"\"\"Forward pass of the Attention layer.\n",
    "\n",
    "        Args:\n",
    "            x (torch.Tensor): Input tensor of shape (batch, T, d_model)\n",
    "\n",
    "        Returns:\n",
    "            torch.Tensor: Output tensor of shape (batch, T, d_V)\n",
    "            torch.Tensor: Attention weights of shape (batch, T, T)\n",
    "        \"\"\"\n",
    "        # Shapes:\n",
    "        # x is a 3d tensor (batch, T, d_model)\n",
    "        # W_K (d_model, d_K)\n",
    "\n",
    "        # (batch, T, d_model) x (d_model, d_K) -> (batch, T, d_K)\n",
    "        K = batched_matmul(x, self.W_K)\n",
    "        Q = batched_matmul(x, self.W_Q)\n",
    "        V = batched_matmul(x, self.W_V)\n",
    "\n",
    "        # (batch, T, d_K) x (batch, d_k, T) -> (batch, T, T)\n",
    "        attention_scores = torch.bmm(Q, K.transpose(1, 2)) / (K.shape[-1] ** 0.5)\n",
    "\n",
    "        if pad_mask is not None:\n",
    "            # (batch, T, T) x (batch, T, 1) -> (batch, T, 1)\n",
    "            attention_scores = attention_scores.masked_fill(pad_mask == 0, 0)\n",
    "\n",
    "        if USE_CAUSAL_MASK:\n",
    "            # Causal mask\n",
    "            # (batch, T, T)\n",
    "            attention_scores = attention_scores.masked_fill(self.causal_mask == 0, -np.inf)\n",
    "\n",
    "        attention_weights = F.softmax(attention_scores, dim=-1)\n",
    "        \n",
    "        # (batch, T, T) x (batch, T, d_V) -> (batch, T, d_V)\n",
    "        attention_scores = torch.bmm(attention_weights, V)\n",
    "\n",
    "        return attention_scores, attention_weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([128, 16])\n",
      "torch.Size([128, 16])\n",
      "torch.Size([128, 16])\n",
      "torch.Size([128, 80, 16])\n"
     ]
    }
   ],
   "source": [
    "att = Attention(d_K=D_K, d_V=D_V, d_model=D_MODEL)\n",
    "x = torch.normal(mean=0, std=0.01, size=(BATCH_SIZE, T, D_MODEL))\n",
    "\n",
    "att_result, att_weights = att.forward(x)\n",
    "assert att_result.shape == (BATCH_SIZE, T, D_V)\n",
    "print(att.W_K.shape)\n",
    "print(att.W_Q.shape)\n",
    "print(att.W_V.shape)\n",
    "print(att_result.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.2. Multi-Head Attention\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MultiHeadAttention(nn.Module):\n",
    "    def __init__(self, h, d_model, d_K, d_V):\n",
    "        super().__init__()\n",
    "        self.h = h\n",
    "        self.attentions = nn.ModuleList(\n",
    "            [Attention(d_K=d_K, d_V=d_V, d_model=d_model) for _ in range(h)]\n",
    "        )\n",
    "        self.W_O = nn.Parameter(torch.normal(mean=0, std=0.01, size=(h * d_V, d_model)))\n",
    "\n",
    "    def forward(self, x: torch.Tensor, pad_mask=None):\n",
    "        \"\"\"Forward pass of the MultiHeadAttention layer.\n",
    "\n",
    "        Args:\n",
    "            x (torch.Tensor): Input tensor of shape (batch, T, d_model)\n",
    "\n",
    "        Returns:\n",
    "            torch.Tensor: Output tensor of shape (batch, T, d_model)\n",
    "            torch.Tensor: Attention weights of shape (batch, h, T, T)\n",
    "        \"\"\"\n",
    "        attention_results = [attention(x, pad_mask)[0] for attention in self.attentions]\n",
    "        attention_weights = torch.stack(\n",
    "            [attention(x, pad_mask)[1] for attention in self.attentions]\n",
    "        )\n",
    "        concatenated = torch.cat(attention_results, dim=-1)\n",
    "        return batched_matmul(concatenated, self.W_O), attention_weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "mha = MultiHeadAttention(h=H, d_K=D_K, d_V=D_V, d_model=D_MODEL)\n",
    "out, att_weights = mha(x)\n",
    "assert out.shape == (BATCH_SIZE, T, D_MODEL)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.3. The transformer block\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Sequential(\n",
       "  (0): Linear(in_features=128, out_features=128, bias=True)\n",
       "  (1): Dropout(p=0.1, inplace=False)\n",
       "  (2): ReLU()\n",
       "  (3): Linear(in_features=128, out_features=128, bias=True)\n",
       "  (4): Dropout(p=0.1, inplace=False)\n",
       ")"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class TransformerBlock(nn.Module):\n",
    "    def __init__(\n",
    "        self, d_K=D_K, d_V=D_V, d_model=D_MODEL, h=H, dropout=0.1, *args, **kwargs\n",
    "    ) -> None:\n",
    "        super().__init__(*args, **kwargs)\n",
    "        self.mha = MultiHeadAttention(h, d_K=d_K, d_V=d_V, d_model=d_model)\n",
    "        self.layer_norm = nn.LayerNorm(d_model)\n",
    "\n",
    "        self.ann = nn.Sequential(\n",
    "            nn.Linear(d_model, d_model),\n",
    "            nn.Dropout(dropout),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(d_model, d_model),\n",
    "            nn.Dropout(dropout),\n",
    "        )\n",
    "\n",
    "    def forward(self, x: torch.Tensor, pad_mask=None):\n",
    "        x = self.layer_norm(x + self.mha(x, pad_mask)[0])\n",
    "        x = self.layer_norm(x + self.ann(x)[0])\n",
    "        return x\n",
    "\n",
    "\n",
    "transformerBlock = TransformerBlock()\n",
    "transformerBlock(x).shape\n",
    "transformerBlock.ann"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.4. The positional encoding\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([80, 128])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def PositionalEncoding(t: int, d_model) -> torch.Tensor:\n",
    "    encodings = torch.zeros(size=(t, d_model), requires_grad=False)\n",
    "    counter = 0\n",
    "    for pos in range(t):\n",
    "        for i in range((d_model // 2) + 1):\n",
    "            if 2 * i < d_model:\n",
    "                counter += 1\n",
    "                encodings[pos, 2 * i] = torch.sin(\n",
    "                    pos / torch.tensor(10000).pow(2 * i / d_model)\n",
    "                )\n",
    "            if 2 * i + 1 < d_model:\n",
    "                counter += 1\n",
    "                encodings[pos, 2 * i + 1] = torch.cos(\n",
    "                    pos / torch.tensor(10000).pow(2 * i / d_model)\n",
    "                )\n",
    "    assert counter == t * d_model\n",
    "    return encodings\n",
    "\n",
    "\n",
    "PositionalEncoding(T, D_MODEL).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_61725/2721896283.py:1: UserWarning: torch.range is deprecated and will be removed in a future release because its behavior is inconsistent with Python's range builtin. Instead, use torch.arange, which produces values in [start, end).\n",
      "  torch.range(0, 10).reshape(-1, 1)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.],\n",
       "        [ 1.],\n",
       "        [ 2.],\n",
       "        [ 3.],\n",
       "        [ 4.],\n",
       "        [ 5.],\n",
       "        [ 6.],\n",
       "        [ 7.],\n",
       "        [ 8.],\n",
       "        [ 9.],\n",
       "        [10.]])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.range(0, 10).reshape(-1, 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.5. The embedding layer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "embedding tensor([[ 0.0699, -0.0838],\n",
      "        [ 0.1141, -0.0243],\n",
      "        [-0.0473,  0.1783]])\n",
      "torch.Size([3, 2])\n",
      "torch.Size([3, 2, 2])\n",
      "tensor([[[-0.0473,  0.1783],\n",
      "         [ 0.1141, -0.0243]],\n",
      "\n",
      "        [[ 0.1141, -0.0243],\n",
      "         [ 0.0699, -0.0838]],\n",
      "\n",
      "        [[ 0.0699, -0.0838],\n",
      "         [-0.0473,  0.1783]]], grad_fn=<IndexBackward0>)\n"
     ]
    }
   ],
   "source": [
    "# TODO: make this work in batches\n",
    "class Embedding(nn.Module):\n",
    "    def __init__(self, vocab_size, d_model, padding_idx=0):\n",
    "        super(Embedding, self).__init__()\n",
    "        self.embedding = nn.Parameter(\n",
    "            torch.normal(\n",
    "                mean=0.0, std=0.1, size=(vocab_size, d_model), requires_grad=True\n",
    "            )\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        \"\"\"forward pass Embedding layer\n",
    "\n",
    "        Args:\n",
    "            x (torch.Tensor): input Tensor of shape (batch_size, T)\n",
    "\n",
    "        Returns:\n",
    "            torch.Tensor: output Tensor of shape (batch_size, T, d_model)\n",
    "        \"\"\"\n",
    "        return self.embedding[x.long()]\n",
    "\n",
    "\n",
    "emb = Embedding(vocab_size=3, d_model=2)\n",
    "# emb = nn.Embedding(num_embeddings=3, embedding_dim=2)\n",
    "for name, param in emb.named_parameters():\n",
    "    print(name, param.data)\n",
    "\n",
    "input_emb = torch.FloatTensor([[2, 1], [1, 0], [0, 2]])\n",
    "\n",
    "print(input_emb.shape)\n",
    "\n",
    "out_emb = emb(input_emb.long())\n",
    "print(out_emb.shape)\n",
    "print(out_emb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Encoder(nn.Module):\n",
    "    def __init__(\n",
    "        self,\n",
    "        t=T,\n",
    "        d_K=D_K,\n",
    "        d_V=D_V,\n",
    "        d_model=D_MODEL,\n",
    "        h=H,\n",
    "        vocab_size=VOCAB_SIZE,\n",
    "        n_transformers=N_TRANSFORMERS_BLOCKS_ENCODER,\n",
    "        dropout=0.1,\n",
    "        *args,\n",
    "        **kwargs\n",
    "    ):\n",
    "        super(Encoder, self).__init__()\n",
    "        self.d_K = d_K\n",
    "        self.d_V = d_V\n",
    "        self.d_model = d_model\n",
    "        self.h = h\n",
    "\n",
    "        self.embedding = Embedding(vocab_size, d_model)\n",
    "        self.position_encoding: torch.Tensor = PositionalEncoding(t, d_model)\n",
    "\n",
    "        self.transformer_blocks = nn.ModuleList()\n",
    "        for _ in range(n_transformers):\n",
    "            self.transformer_blocks.append(\n",
    "                TransformerBlock(d_K=d_K, d_V=d_V, d_model=d_model, h=h)\n",
    "            )\n",
    "\n",
    "    def forward(self, x: torch.Tensor, pad_mask=None):\n",
    "        # if pad_mask is not None:\n",
    "        #     assert pad_mask.shape == x.shape\n",
    "        #     x = x.masked_fill(pad_mask == 0, 0)\n",
    "        batchedPositionalEncoding = self.position_encoding.repeat(x.shape[0], 1, 1)\n",
    "        x = self.embedding(x.int()).float()\n",
    "        x = x + batchedPositionalEncoding\n",
    "\n",
    "        for block in self.transformer_blocks:\n",
    "            x = block(x)\n",
    "\n",
    "        return x\n",
    "\n",
    "    def to(self, *args, **kwargs):\n",
    "        self.position_encoding = self.position_encoding.to(*args, **kwargs)\n",
    "        return super().to(*args, **kwargs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.6. The Classification Encoder\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ClassifierEncoder(Encoder):\n",
    "    def __init__(\n",
    "        self,\n",
    "        n_classes,\n",
    "        t=T,\n",
    "        d_K=D_K,\n",
    "        d_V=D_V,\n",
    "        d_model=D_MODEL,\n",
    "        h=H,\n",
    "        vocab_size=VOCAB_SIZE,\n",
    "        n_transformers=N_TRANSFORMERS_BLOCKS_ENCODER,\n",
    "        dropout=0.1,\n",
    "        *args,\n",
    "        **kwargs\n",
    "    ):\n",
    "        super(ClassifierEncoder, self).__init__()\n",
    "        self.d_K = d_K\n",
    "        self.d_V = d_V\n",
    "        self.d_model = d_model\n",
    "        self.h = h\n",
    "        self.n_classes = n_classes\n",
    "\n",
    "        self.embedding = Embedding(vocab_size, d_model)\n",
    "        self.position_encoding: torch.Tensor = PositionalEncoding(t, d_model)\n",
    "\n",
    "        self.transformer_blocks = nn.ModuleList()\n",
    "        for _ in range(n_transformers):\n",
    "            self.transformer_blocks.append(\n",
    "                TransformerBlock(d_K=d_K, d_V=d_V, d_model=d_model, h=h)\n",
    "            )\n",
    "\n",
    "        self.prediction_head = nn.Linear(self.d_model, n_classes)\n",
    "        self.n_classes = n_classes\n",
    "        self.prediction_head = nn.Linear(self.d_model, n_classes)\n",
    "\n",
    "    def forward(self, x: torch.Tensor, pad_mask=None):\n",
    "        # if pad_mask is not None:\n",
    "        #     x = x * pad_mask\n",
    "        x = super().forward(x, pad_mask)\n",
    "        x = self.prediction_head(x)\n",
    "        x = F.softmax(x, dim=-1)\n",
    "        x = x[:, -1, :]\n",
    "\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Let's try a classification problem using the CLassification Encoder\n",
    "* See the file: Fine-Tuning (Intermediate)/Fine-Tunning Sentiment Custom Dataset + Labels.ipynb\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## First, lets make a dataset with cross validation\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweet_id</th>\n",
       "      <th>airline_sentiment</th>\n",
       "      <th>airline_sentiment_confidence</th>\n",
       "      <th>negativereason</th>\n",
       "      <th>negativereason_confidence</th>\n",
       "      <th>airline</th>\n",
       "      <th>airline_sentiment_gold</th>\n",
       "      <th>name</th>\n",
       "      <th>negativereason_gold</th>\n",
       "      <th>retweet_count</th>\n",
       "      <th>text</th>\n",
       "      <th>tweet_coord</th>\n",
       "      <th>tweet_created</th>\n",
       "      <th>tweet_location</th>\n",
       "      <th>user_timezone</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>570306133677760513</td>\n",
       "      <td>neutral</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Virgin America</td>\n",
       "      <td>NaN</td>\n",
       "      <td>cairdin</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>@VirginAmerica What @dhepburn said.</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2015-02-24 11:35:52 -0800</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Eastern Time (US &amp; Canada)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>570301130888122368</td>\n",
       "      <td>positive</td>\n",
       "      <td>0.3486</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>Virgin America</td>\n",
       "      <td>NaN</td>\n",
       "      <td>jnardino</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>@VirginAmerica plus you've added commercials t...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2015-02-24 11:15:59 -0800</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Pacific Time (US &amp; Canada)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>570301083672813571</td>\n",
       "      <td>neutral</td>\n",
       "      <td>0.6837</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Virgin America</td>\n",
       "      <td>NaN</td>\n",
       "      <td>yvonnalynn</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>@VirginAmerica I didn't today... Must mean I n...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2015-02-24 11:15:48 -0800</td>\n",
       "      <td>Lets Play</td>\n",
       "      <td>Central Time (US &amp; Canada)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>570301031407624196</td>\n",
       "      <td>negative</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>Bad Flight</td>\n",
       "      <td>0.7033</td>\n",
       "      <td>Virgin America</td>\n",
       "      <td>NaN</td>\n",
       "      <td>jnardino</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>@VirginAmerica it's really aggressive to blast...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2015-02-24 11:15:36 -0800</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Pacific Time (US &amp; Canada)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>570300817074462722</td>\n",
       "      <td>negative</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>Can't Tell</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>Virgin America</td>\n",
       "      <td>NaN</td>\n",
       "      <td>jnardino</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>@VirginAmerica and it's a really big bad thing...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2015-02-24 11:14:45 -0800</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Pacific Time (US &amp; Canada)</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             tweet_id airline_sentiment  airline_sentiment_confidence  \\\n",
       "0  570306133677760513           neutral                        1.0000   \n",
       "1  570301130888122368          positive                        0.3486   \n",
       "2  570301083672813571           neutral                        0.6837   \n",
       "3  570301031407624196          negative                        1.0000   \n",
       "4  570300817074462722          negative                        1.0000   \n",
       "\n",
       "  negativereason  negativereason_confidence         airline  \\\n",
       "0            NaN                        NaN  Virgin America   \n",
       "1            NaN                     0.0000  Virgin America   \n",
       "2            NaN                        NaN  Virgin America   \n",
       "3     Bad Flight                     0.7033  Virgin America   \n",
       "4     Can't Tell                     1.0000  Virgin America   \n",
       "\n",
       "  airline_sentiment_gold        name negativereason_gold  retweet_count  \\\n",
       "0                    NaN     cairdin                 NaN              0   \n",
       "1                    NaN    jnardino                 NaN              0   \n",
       "2                    NaN  yvonnalynn                 NaN              0   \n",
       "3                    NaN    jnardino                 NaN              0   \n",
       "4                    NaN    jnardino                 NaN              0   \n",
       "\n",
       "                                                text tweet_coord  \\\n",
       "0                @VirginAmerica What @dhepburn said.         NaN   \n",
       "1  @VirginAmerica plus you've added commercials t...         NaN   \n",
       "2  @VirginAmerica I didn't today... Must mean I n...         NaN   \n",
       "3  @VirginAmerica it's really aggressive to blast...         NaN   \n",
       "4  @VirginAmerica and it's a really big bad thing...         NaN   \n",
       "\n",
       "               tweet_created tweet_location               user_timezone  \n",
       "0  2015-02-24 11:35:52 -0800            NaN  Eastern Time (US & Canada)  \n",
       "1  2015-02-24 11:15:59 -0800            NaN  Pacific Time (US & Canada)  \n",
       "2  2015-02-24 11:15:48 -0800      Lets Play  Central Time (US & Canada)  \n",
       "3  2015-02-24 11:15:36 -0800            NaN  Pacific Time (US & Canada)  \n",
       "4  2015-02-24 11:14:45 -0800            NaN  Pacific Time (US & Canada)  "
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_ = pd.read_csv(\"../Fine-Tuning (Intermediate)/AirlineTweets.csv\")\n",
    "df_.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot: >"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "df_['airline_sentiment'].hist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>airline_sentiment</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>neutral</td>\n",
       "      <td>@VirginAmerica What @dhepburn said.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>positive</td>\n",
       "      <td>@VirginAmerica plus you've added commercials t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>neutral</td>\n",
       "      <td>@VirginAmerica I didn't today... Must mean I n...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>negative</td>\n",
       "      <td>@VirginAmerica it's really aggressive to blast...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>negative</td>\n",
       "      <td>@VirginAmerica and it's a really big bad thing...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  airline_sentiment                                               text\n",
       "0           neutral                @VirginAmerica What @dhepburn said.\n",
       "1          positive  @VirginAmerica plus you've added commercials t...\n",
       "2           neutral  @VirginAmerica I didn't today... Must mean I n...\n",
       "3          negative  @VirginAmerica it's really aggressive to blast...\n",
       "4          negative  @VirginAmerica and it's a really big bad thing..."
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = df_[[\"airline_sentiment\", \"text\"]].copy()\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>airline_sentiment</th>\n",
       "      <th>text</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>neutral</td>\n",
       "      <td>@VirginAmerica What @dhepburn said.</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>positive</td>\n",
       "      <td>@VirginAmerica plus you've added commercials t...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>neutral</td>\n",
       "      <td>@VirginAmerica I didn't today... Must mean I n...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>negative</td>\n",
       "      <td>@VirginAmerica it's really aggressive to blast...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>negative</td>\n",
       "      <td>@VirginAmerica and it's a really big bad thing...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  airline_sentiment                                               text  target\n",
       "0           neutral                @VirginAmerica What @dhepburn said.       2\n",
       "1          positive  @VirginAmerica plus you've added commercials t...       1\n",
       "2           neutral  @VirginAmerica I didn't today... Must mean I n...       2\n",
       "3          negative  @VirginAmerica it's really aggressive to blast...       0\n",
       "4          negative  @VirginAmerica and it's a really big bad thing...       0"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "target_map = {\n",
    "    \"positive\": 1,\n",
    "    \"negative\": 0,\n",
    "    \"neutral\": 2,\n",
    "}\n",
    "inverse_target_map = {v: k for k, v in target_map.items()}\n",
    "df[\"target\"] = df[\"airline_sentiment\"].map(target_map)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>airline_sentiment</th>\n",
       "      <th>text</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>positive</td>\n",
       "      <td>@VirginAmerica plus you've added commercials t...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>negative</td>\n",
       "      <td>@VirginAmerica it's really aggressive to blast...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>negative</td>\n",
       "      <td>@VirginAmerica and it's a really big bad thing...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>negative</td>\n",
       "      <td>@VirginAmerica seriously would pay $30 a fligh...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>positive</td>\n",
       "      <td>@VirginAmerica yes, nearly every time I fly VX...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  airline_sentiment                                               text  target\n",
       "1          positive  @VirginAmerica plus you've added commercials t...       1\n",
       "3          negative  @VirginAmerica it's really aggressive to blast...       0\n",
       "4          negative  @VirginAmerica and it's a really big bad thing...       0\n",
       "5          negative  @VirginAmerica seriously would pay $30 a fligh...       0\n",
       "6          positive  @VirginAmerica yes, nearly every time I fly VX...       1"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_filtered = df[df[\"target\"] != 2]\n",
    "df_filtered.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sentence,label\n",
      "@VirginAmerica plus you've added commercials to the experience... tacky.,1\n",
      "\"@VirginAmerica it's really aggressive to blast obnoxious \"\"entertainment\"\" in your guests' faces &amp; they have little recourse\",0\n",
      "@VirginAmerica and it's a really big bad thing about it,0\n",
      "\"@VirginAmerica seriously would pay $30 a flight for seats that didn't have this playing.\n",
      "it's really the only bad thing about flying VA\",0\n",
      "\"@VirginAmerica yes, nearly every time I fly VX this ear worm wont go away :)\",1\n",
      "\"@virginamerica Well, I didn'tbut NOW I DO! :-D\",1\n",
      "\"@VirginAmerica it was amazing, and arrived an hour early. You're too good to me.\",1\n",
      "@VirginAmerica I &lt;3 pretty graphics. so much better than minimal iconography. :D,1\n"
     ]
    }
   ],
   "source": [
    "df2 = df_filtered[['text', 'target']]\n",
    "# Not documented info: targets must have the column name label\n",
    "# sentence may have other names, but not label\n",
    "df2.columns = ['sentence', 'label']\n",
    "df2.to_csv(\"data.csv\", index=False)\n",
    "!head data.csv\n",
    "# df2.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8bc0629caad14ef89d024b27fedba2e5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading data files:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b0be3770b0f143118cf5491414d94d62",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Extracting data files:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7232db481cbe4aa989ed1a013f6a13fe",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating train split: 0 examples [00:00, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "raw_dataset = load_dataset(\"csv\", data_files=\"data.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['sentence', 'label'],\n",
       "        num_rows: 11541\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raw_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def splitTrainTestValidation(dataset: Dataset, valid_size=0.1, test_size=0.1):\n",
    "    len_valid = int(len(dataset) * valid_size)\n",
    "    len_test = int(len(dataset) * test_size)\n",
    "\n",
    "    splited: DatasetDict = dataset.train_test_split(\n",
    "        len_valid + len_test, shuffle=False, seed=42\n",
    "    )\n",
    "    splited[\"validation\"] = splited[\"test\"]\n",
    "    del splited[\"test\"]\n",
    "\n",
    "    splited_2 = splited[\"validation\"].train_test_split(len_test, shuffle=True, seed=42)\n",
    "    splited[\"validation\"] = splited_2[\"train\"]\n",
    "    splited[\"test\"] = splited_2[\"test\"]\n",
    "\n",
    "    return splited"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split = raw_dataset['train'].train_test_split(test_size=.3, seed=42)\n",
    "split = splitTrainTestValidation(raw_dataset[\"train\"], valid_size=0.1, test_size=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['sentence', 'label'],\n",
       "        num_rows: 9233\n",
       "    })\n",
       "    validation: Dataset({\n",
       "        features: ['sentence', 'label'],\n",
       "        num_rows: 1154\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['sentence', 'label'],\n",
       "        num_rows: 1154\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint = \"distilbert-base-cased\"\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(checkpoint)\n",
    "\n",
    "\n",
    "def tokenize_fn(batch):\n",
    "    return tokenizer(\n",
    "        batch[\"sentence\"], truncation=True, padding=\"max_length\", max_length=T\n",
    "    )\n",
    "\n",
    "\n",
    "# tokenizer(\"This is an example\", truncation=True, padding=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3dd7d229fc754387b69bc820b3571b96",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/9233 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3f0f0817e5a7422ba207981a882fc549",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/1154 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e54d7bf4250740c5862a9071032377f9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/1154 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['sentence', 'label', 'input_ids', 'attention_mask'],\n",
       "        num_rows: 9233\n",
       "    })\n",
       "    validation: Dataset({\n",
       "        features: ['sentence', 'label', 'input_ids', 'attention_mask'],\n",
       "        num_rows: 1154\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['sentence', 'label', 'input_ids', 'attention_mask'],\n",
       "        num_rows: 1154\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenized_datasets = split.map(tokenize_fn, batched=False)\n",
    "tokenized_datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "647686b04c9c43dbb1a4dc7b2c35df27",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Filter:   0%|          | 0/1154 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8a61ad18f62a4177ba78ee082f5f74ab",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Filter:   0%|          | 0/1154 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['sentence', 'label', 'input_ids', 'attention_mask'],\n",
       "        num_rows: 9233\n",
       "    })\n",
       "    validation: Dataset({\n",
       "        features: ['sentence', 'label', 'input_ids', 'attention_mask'],\n",
       "        num_rows: 853\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['sentence', 'label', 'input_ids', 'attention_mask'],\n",
       "        num_rows: 844\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Little notation here:\n",
    "# token is an int from the tokenizer\n",
    "# idx is our index, to use in our embedding\n",
    "\n",
    "token2idx = {0: 0}\n",
    "idx2token = {}\n",
    "\n",
    "all_tokens = [\n",
    "    element\n",
    "    for list_ids in tokenized_datasets[\"train\"][\"input_ids\"]\n",
    "    for element in list_ids\n",
    "]\n",
    "all_tokens = list(set(all_tokens))\n",
    "\n",
    "token_index = 0\n",
    "for token in all_tokens:\n",
    "    if token not in token2idx:\n",
    "        token2idx[token] = token_index\n",
    "        idx2token[token_index] = token\n",
    "        token_index += 1\n",
    "\n",
    "\n",
    "def filterSplit(splited_dataset):\n",
    "    \"\"\"For valid and test datasets, get only those which all inpu_ids is in splited_dataset['train']\"\"\"\n",
    "\n",
    "    for split in [\"validation\", \"test\"]:\n",
    "        # Filter the splited_dataset[split] to only keep the ids which are in splited_dataset['train']\n",
    "        splited_dataset[split] = splited_dataset[split].filter(\n",
    "            lambda x: all(token in token2idx for token in x[\"input_ids\"])\n",
    "        )\n",
    "\n",
    "    return splited_dataset\n",
    "\n",
    "\n",
    "filtered_datasets = filterSplit(tokenized_datasets)\n",
    "filtered_datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vamos construir nosso dicionrio de tokens\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "07c6a9995c414b9c8bb9274d84947ce9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/9233 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "080251f5dfcb40e7aa761d75708db54d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/853 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bb2980cb036b48e0b8b8906ae033d062",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/844 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['sentence', 'label', 'input_ids', 'attention_mask', 'input_idx'],\n",
       "        num_rows: 9233\n",
       "    })\n",
       "    validation: Dataset({\n",
       "        features: ['sentence', 'label', 'input_ids', 'attention_mask', 'input_idx'],\n",
       "        num_rows: 853\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['sentence', 'label', 'input_ids', 'attention_mask', 'input_idx'],\n",
       "        num_rows: 844\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def makeIndex(batch):\n",
    "    batch[\"input_idx\"] = [token2idx[token_id] for token_id in batch[\"input_ids\"]]\n",
    "    return batch\n",
    "\n",
    "\n",
    "data = filtered_datasets.map(makeIndex, batched=False)\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1300x400 with 3 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "data_labels = {\n",
    "    \"Train\": data[\"train\"][\"label\"],\n",
    "    \"Validation\": data[\"validation\"][\"label\"],\n",
    "    \"Test\": data[\"test\"][\"label\"],\n",
    "}\n",
    "\n",
    "fig, axs = plt.subplots(1, 3, figsize=(13, 4))\n",
    "\n",
    "for i, (label_name, labels) in enumerate(data_labels.items()):\n",
    "    axs[i].hist(labels, alpha=0.5, label=label_name)\n",
    "    axs[i].set_xlabel(\"Label\")\n",
    "    axs[i].set_ylabel(\"Count\")\n",
    "    axs[i].set_title(f\"Histogram of {label_name} Labels\")\n",
    "    axs[i].legend()\n",
    "\n",
    "plt.subplots_adjust(wspace=8)  # Adjust the space between the subplots\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[80]"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Assert all same length\n",
    "list(set([len(l_idx) for l_idx in data[\"train\"][\"input_idx\"]]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([9233, 80])"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_train = torch.Tensor(data[\"train\"][\"input_idx\"]).type(torch.int32)\n",
    "mask_train = torch.Tensor(data[\"train\"][\"attention_mask\"]).type(torch.int32)\n",
    "input_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0., 1.],\n",
       "        [1., 0.],\n",
       "        [1., 0.],\n",
       "        [1., 0.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.]])"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "target_train = torch.Tensor(data[\"train\"][\"label\"])\n",
    "\n",
    "# make one_hot\n",
    "target_train = F.one_hot(target_train.to(torch.int64), num_classes=N_CLASSES).float()\n",
    "\n",
    "target_train[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([853, 80])"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_valid = torch.Tensor(data[\"validation\"][\"input_idx\"]).type(torch.int32)\n",
    "mask_valid = torch.Tensor(data[\"validation\"][\"attention_mask\"]).type(torch.int32)\n",
    "input_valid.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1., 0.],\n",
       "        [1., 0.],\n",
       "        [1., 0.],\n",
       "        [1., 0.],\n",
       "        [1., 0.],\n",
       "        [1., 0.],\n",
       "        [1., 0.],\n",
       "        [1., 0.],\n",
       "        [0., 1.],\n",
       "        [1., 0.]])"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "target_valid = torch.Tensor(data[\"validation\"][\"label\"])\n",
    "\n",
    "# make one_hot\n",
    "target_valid = F.one_hot(target_valid.to(torch.int64), num_classes=N_CLASSES).float()\n",
    "\n",
    "target_valid[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([844, 80])"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_test = torch.Tensor(data[\"test\"][\"input_idx\"]).type(torch.int32)\n",
    "mask_test = torch.Tensor(data[\"test\"][\"attention_mask\"]).type(torch.int32)\n",
    "input_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1., 0.],\n",
       "        [1., 0.],\n",
       "        [1., 0.],\n",
       "        [1., 0.],\n",
       "        [1., 0.],\n",
       "        [1., 0.],\n",
       "        [0., 1.],\n",
       "        [1., 0.],\n",
       "        [1., 0.],\n",
       "        [1., 0.]])"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "target_test = torch.Tensor(data[\"test\"][\"label\"])\n",
    "\n",
    "# make one_hot\n",
    "target_test = F.one_hot(target_test.to(torch.int64), num_classes=N_CLASSES).float()\n",
    "\n",
    "target_test[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Now let's train our model! \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 1 [1152/9233 (12%)]\tTrain loss (avg): 0.003970\n",
      "Train Epoch: 1 [2432/9233 (26%)]\tTrain loss (avg): 0.004185\n",
      "Train Epoch: 1 [3712/9233 (40%)]\tTrain loss (avg): 0.004168\n",
      "Train Epoch: 1 [4992/9233 (53%)]\tTrain loss (avg): 0.004142\n",
      "Train Epoch: 1 [6272/9233 (67%)]\tTrain loss (avg): 0.004152\n",
      "Train Epoch: 1 [7552/9233 (81%)]\tTrain loss (avg): 0.004160\n",
      "Train Epoch: 1 [8832/9233 (95%)]\tTrain loss (avg): 0.004148\n",
      "\n",
      "Average loss (validation): 0.003763, Accuracy: 717/853 (84.06%)\n",
      "\n",
      "Epoch: 1\tloss (validation): 0.003762977553699668\n",
      "Train Epoch: 2 [1152/9233 (12%)]\tTrain loss (avg): 0.004227\n",
      "Train Epoch: 2 [2432/9233 (26%)]\tTrain loss (avg): 0.004135\n",
      "Train Epoch: 2 [3712/9233 (40%)]\tTrain loss (avg): 0.004202\n",
      "Train Epoch: 2 [4992/9233 (53%)]\tTrain loss (avg): 0.004198\n",
      "Train Epoch: 2 [6272/9233 (67%)]\tTrain loss (avg): 0.004191\n",
      "Train Epoch: 2 [7552/9233 (81%)]\tTrain loss (avg): 0.004174\n",
      "Train Epoch: 2 [8832/9233 (95%)]\tTrain loss (avg): 0.004128\n",
      "\n",
      "Average loss (validation): 0.003526, Accuracy: 717/853 (84.06%)\n",
      "\n",
      "Epoch: 2\tloss (validation): 0.003525661450896984\n",
      "Train Epoch: 3 [1152/9233 (12%)]\tTrain loss (avg): 0.004089\n",
      "Train Epoch: 3 [2432/9233 (26%)]\tTrain loss (avg): 0.004135\n",
      "Train Epoch: 3 [3712/9233 (40%)]\tTrain loss (avg): 0.004086\n",
      "Train Epoch: 3 [4992/9233 (53%)]\tTrain loss (avg): 0.004021\n",
      "Train Epoch: 3 [6272/9233 (67%)]\tTrain loss (avg): 0.003971\n",
      "Train Epoch: 3 [7552/9233 (81%)]\tTrain loss (avg): 0.003911\n",
      "Train Epoch: 3 [8832/9233 (95%)]\tTrain loss (avg): 0.003882\n",
      "\n",
      "Average loss (validation): 0.002881, Accuracy: 743/853 (87.10%)\n",
      "\n",
      "Epoch: 3\tloss (validation): 0.0028805083923854136\n",
      "Train Epoch: 4 [1152/9233 (12%)]\tTrain loss (avg): 0.003740\n",
      "Train Epoch: 4 [2432/9233 (26%)]\tTrain loss (avg): 0.003457\n",
      "Train Epoch: 4 [3712/9233 (40%)]\tTrain loss (avg): 0.003492\n",
      "Train Epoch: 4 [4992/9233 (53%)]\tTrain loss (avg): 0.003416\n",
      "Train Epoch: 4 [6272/9233 (67%)]\tTrain loss (avg): 0.003377\n",
      "Train Epoch: 4 [7552/9233 (81%)]\tTrain loss (avg): 0.003366\n",
      "Train Epoch: 4 [8832/9233 (95%)]\tTrain loss (avg): 0.003316\n",
      "\n",
      "Average loss (validation): 0.002451, Accuracy: 753/853 (88.28%)\n",
      "\n",
      "Epoch: 4\tloss (validation): 0.0024511353281989326\n",
      "Train Epoch: 5 [1152/9233 (12%)]\tTrain loss (avg): 0.003024\n",
      "Train Epoch: 5 [2432/9233 (26%)]\tTrain loss (avg): 0.003011\n",
      "Train Epoch: 5 [3712/9233 (40%)]\tTrain loss (avg): 0.002955\n",
      "Train Epoch: 5 [4992/9233 (53%)]\tTrain loss (avg): 0.002941\n",
      "Train Epoch: 5 [6272/9233 (67%)]\tTrain loss (avg): 0.002922\n",
      "Train Epoch: 5 [7552/9233 (81%)]\tTrain loss (avg): 0.002898\n",
      "Train Epoch: 5 [8832/9233 (95%)]\tTrain loss (avg): 0.002844\n",
      "\n",
      "Average loss (validation): 0.002633, Accuracy: 752/853 (88.16%)\n",
      "\n",
      "Epoch: 5\tloss (validation): 0.0026330984910515522\n",
      "Train Epoch: 6 [1152/9233 (12%)]\tTrain loss (avg): 0.003053\n",
      "Train Epoch: 6 [2432/9233 (26%)]\tTrain loss (avg): 0.002798\n",
      "Train Epoch: 6 [3712/9233 (40%)]\tTrain loss (avg): 0.002651\n",
      "Train Epoch: 6 [4992/9233 (53%)]\tTrain loss (avg): 0.002578\n",
      "Train Epoch: 6 [6272/9233 (67%)]\tTrain loss (avg): 0.002484\n",
      "Train Epoch: 6 [7552/9233 (81%)]\tTrain loss (avg): 0.002426\n",
      "Train Epoch: 6 [8832/9233 (95%)]\tTrain loss (avg): 0.002467\n",
      "\n",
      "Average loss (validation): 0.001993, Accuracy: 774/853 (90.74%)\n",
      "\n",
      "Epoch: 6\tloss (validation): 0.0019934353662124133\n",
      "Train Epoch: 7 [1152/9233 (12%)]\tTrain loss (avg): 0.002191\n",
      "Train Epoch: 7 [2432/9233 (26%)]\tTrain loss (avg): 0.002160\n",
      "Train Epoch: 7 [3712/9233 (40%)]\tTrain loss (avg): 0.002116\n",
      "Train Epoch: 7 [4992/9233 (53%)]\tTrain loss (avg): 0.002081\n",
      "Train Epoch: 7 [6272/9233 (67%)]\tTrain loss (avg): 0.002063\n",
      "Train Epoch: 7 [7552/9233 (81%)]\tTrain loss (avg): 0.002051\n",
      "Train Epoch: 7 [8832/9233 (95%)]\tTrain loss (avg): 0.002070\n",
      "\n",
      "Average loss (validation): 0.001914, Accuracy: 782/853 (91.68%)\n",
      "\n",
      "Epoch: 7\tloss (validation): 0.0019139165161363126\n",
      "Train Epoch: 8 [1152/9233 (12%)]\tTrain loss (avg): 0.001941\n",
      "Train Epoch: 8 [2432/9233 (26%)]\tTrain loss (avg): 0.001897\n",
      "Train Epoch: 8 [3712/9233 (40%)]\tTrain loss (avg): 0.001869\n",
      "Train Epoch: 8 [4992/9233 (53%)]\tTrain loss (avg): 0.001862\n",
      "Train Epoch: 8 [6272/9233 (67%)]\tTrain loss (avg): 0.001842\n",
      "Train Epoch: 8 [7552/9233 (81%)]\tTrain loss (avg): 0.001826\n",
      "Train Epoch: 8 [8832/9233 (95%)]\tTrain loss (avg): 0.001836\n",
      "\n",
      "Average loss (validation): 0.001909, Accuracy: 781/853 (91.56%)\n",
      "\n",
      "Epoch: 8\tloss (validation): 0.0019085143298644394\n",
      "Train Epoch: 9 [1152/9233 (12%)]\tTrain loss (avg): 0.001812\n",
      "Train Epoch: 9 [2432/9233 (26%)]\tTrain loss (avg): 0.001838\n",
      "Train Epoch: 9 [3712/9233 (40%)]\tTrain loss (avg): 0.001828\n",
      "Train Epoch: 9 [4992/9233 (53%)]\tTrain loss (avg): 0.001811\n",
      "Train Epoch: 9 [6272/9233 (67%)]\tTrain loss (avg): 0.001828\n",
      "Train Epoch: 9 [7552/9233 (81%)]\tTrain loss (avg): 0.001824\n",
      "Train Epoch: 9 [8832/9233 (95%)]\tTrain loss (avg): 0.001808\n",
      "\n",
      "Average loss (validation): 0.001779, Accuracy: 789/853 (92.50%)\n",
      "\n",
      "Epoch: 9\tloss (validation): 0.0017790254052610498\n",
      "Train Epoch: 10 [1152/9233 (12%)]\tTrain loss (avg): 0.001519\n",
      "Train Epoch: 10 [2432/9233 (26%)]\tTrain loss (avg): 0.001505\n",
      "Train Epoch: 10 [3712/9233 (40%)]\tTrain loss (avg): 0.001617\n",
      "Train Epoch: 10 [4992/9233 (53%)]\tTrain loss (avg): 0.001635\n",
      "Train Epoch: 10 [6272/9233 (67%)]\tTrain loss (avg): 0.001625\n",
      "Train Epoch: 10 [7552/9233 (81%)]\tTrain loss (avg): 0.001589\n",
      "Train Epoch: 10 [8832/9233 (95%)]\tTrain loss (avg): 0.001578\n",
      "\n",
      "Average loss (validation): 0.001841, Accuracy: 787/853 (92.26%)\n",
      "\n",
      "Epoch: 10\tloss (validation): 0.001840560353095758\n",
      "Train Epoch: 11 [1152/9233 (12%)]\tTrain loss (avg): 0.001342\n",
      "Train Epoch: 11 [2432/9233 (26%)]\tTrain loss (avg): 0.001416\n",
      "Train Epoch: 11 [3712/9233 (40%)]\tTrain loss (avg): 0.001433\n",
      "Train Epoch: 11 [4992/9233 (53%)]\tTrain loss (avg): 0.001427\n",
      "Train Epoch: 11 [6272/9233 (67%)]\tTrain loss (avg): 0.001433\n",
      "Train Epoch: 11 [7552/9233 (81%)]\tTrain loss (avg): 0.001434\n",
      "Train Epoch: 11 [8832/9233 (95%)]\tTrain loss (avg): 0.001450\n",
      "\n",
      "Average loss (validation): 0.001869, Accuracy: 781/853 (91.56%)\n",
      "\n",
      "Epoch: 11\tloss (validation): 0.0018690815424723475\n",
      "Train Epoch: 12 [1152/9233 (12%)]\tTrain loss (avg): 0.001210\n",
      "Train Epoch: 12 [2432/9233 (26%)]\tTrain loss (avg): 0.001237\n",
      "Train Epoch: 12 [3712/9233 (40%)]\tTrain loss (avg): 0.001258\n",
      "Train Epoch: 12 [4992/9233 (53%)]\tTrain loss (avg): 0.001274\n",
      "Train Epoch: 12 [6272/9233 (67%)]\tTrain loss (avg): 0.001248\n",
      "Train Epoch: 12 [7552/9233 (81%)]\tTrain loss (avg): 0.001259\n",
      "Train Epoch: 12 [8832/9233 (95%)]\tTrain loss (avg): 0.001264\n",
      "\n",
      "Average loss (validation): 0.001792, Accuracy: 791/853 (92.73%)\n",
      "\n",
      "Epoch: 12\tloss (validation): 0.0017918327524122572\n",
      "\n",
      "Average loss (test): 0.001499, Accuracy: 786/844 (93.13%)\n",
      "\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x500 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def evaluate(model, eval_loader, criterion, verbose=False, type_loss=\"validation\"):\n",
    "    model = model.to(device)\n",
    "    model.eval()\n",
    "    loss = 0.0\n",
    "    total = 0\n",
    "    correct = 0\n",
    "    with torch.no_grad():\n",
    "        for inputs_, target, mask in eval_loader:\n",
    "            inputs_, target, mask = (\n",
    "                inputs_.to(device),\n",
    "                target.to(device),\n",
    "                mask.to(device),\n",
    "            )\n",
    "            # if USE_CAUSAL_MASK:\n",
    "            output = model(inputs_, mask)\n",
    "            # else:\n",
    "            #     output = model(inputs_)\n",
    "\n",
    "            if type(criterion) == torch.nn.modules.loss.NLLLoss:\n",
    "                loss += criterion(output, target.argmax(dim=-1)).item()\n",
    "            else:\n",
    "                loss += criterion(output, target).item()\n",
    "            pred = output.argmax(dim=1, keepdim=True)\n",
    "            target_ = target.argmax(dim=1, keepdim=True)\n",
    "            correct += pred.eq(target_).sum().item()\n",
    "            total += target.size(0)\n",
    "\n",
    "    loss /= len(eval_loader.dataset)\n",
    "    accuracy = 100.0 * correct / total\n",
    "    verbose and print(\n",
    "        \"\\nAverage loss ({}): {:.6f}, Accuracy: {}/{} ({:.2f}%)\\n\".format(\n",
    "            type_loss,\n",
    "            loss,\n",
    "            correct,\n",
    "            total,\n",
    "            accuracy,\n",
    "        )\n",
    "    )\n",
    "    return loss\n",
    "\n",
    "\n",
    "def train(model, train_loader, optimizer, criterion, epoch):\n",
    "    total_loss = 0\n",
    "    model = model.to(device)\n",
    "    model.train()\n",
    "    for batch_idx, (input_, target, mask) in enumerate(train_loader):\n",
    "        input_, target, mask = (\n",
    "            input_.to(device),\n",
    "            target.to(device),\n",
    "            mask.to(device),\n",
    "        )\n",
    "        optimizer.zero_grad()\n",
    "        # if USE_CAUSAL_MASK:\n",
    "        output = model(input_, mask)\n",
    "        # else:\n",
    "        #     output = model(input_)\n",
    "        if type(criterion) == torch.nn.modules.loss.NLLLoss:\n",
    "            loss = criterion(output, target.argmax(dim=-1))\n",
    "        else:\n",
    "            loss = criterion(output, target)\n",
    "        total_loss += loss.item()\n",
    "        avg_loss = total_loss / (batch_idx + 1) / len(input_)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        # valid_loss = evaluate(model, validation_loader, criterion)\n",
    "        # if valid_loss < best_loss:\n",
    "        #     best_loss = valid_loss\n",
    "        #     torch.save(model.state_dict(), \"model.pth\")\n",
    "\n",
    "        if (batch_idx + 1) % LOG_INTERVAL_IN_BATCHES == 0:\n",
    "            print(\n",
    "                \"Train Epoch: {} [{}/{} ({:.0f}%)]\\tTrain loss (avg): {:.6f}\".format(\n",
    "                    epoch,\n",
    "                    batch_idx * len(input_),\n",
    "                    len(train_loader.dataset),\n",
    "                    100.0 * batch_idx / len(train_loader),\n",
    "                    avg_loss,\n",
    "                )\n",
    "            )\n",
    "\n",
    "\n",
    "class MyDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, inputs, target, attention_mask=None):\n",
    "        self.inputs = inputs\n",
    "        self.target = target\n",
    "        if attention_mask is not None:\n",
    "            self.attention_mask = attention_mask\n",
    "        else:\n",
    "            self.attention_mask = torch.ones_like(inputs)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.inputs)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.inputs[idx], self.target[idx], self.attention_mask[idx]\n",
    "\n",
    "\n",
    "model = ClassifierEncoder(\n",
    "    n_classes=N_CLASSES,\n",
    "    t=T,\n",
    "    d_K=D_K,\n",
    "    d_V=D_V,\n",
    "    d_model=D_MODEL,\n",
    "    h=H,\n",
    "    vocab_size=len(token2idx),\n",
    "    n_transformers=N_TRANSFORMERS_BLOCKS_ENCODER,\n",
    ")\n",
    "\n",
    "train_dataset = MyDataset(input_train, target_train, attention_mask=mask_train)\n",
    "train_loader = torch.utils.data.DataLoader(\n",
    "    train_dataset, batch_size=BATCH_SIZE, shuffle=True\n",
    ")\n",
    "\n",
    "valid_dataset = MyDataset(input_valid, target_valid, attention_mask=mask_valid)\n",
    "valid_loader = torch.utils.data.DataLoader(valid_dataset, batch_size=BATCH_SIZE)\n",
    "\n",
    "test_dataset = MyDataset(input_test, target_test, attention_mask=mask_test)\n",
    "test_loader = torch.utils.data.DataLoader(test_dataset, batch_size=BATCH_SIZE)\n",
    "\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.0001)\n",
    "# criterion = torch.nn.NLLLoss()\n",
    "criterion = torch.nn.BCELoss()\n",
    "\n",
    "best_loss = np.inf\n",
    "valid_losses = []\n",
    "\n",
    "\n",
    "def plotLosses(losses, loss_type=\"validation\"):\n",
    "    plt.figure(figsize=(10, 5))\n",
    "    plt.plot(losses)\n",
    "    plt.title(f\"Model loss ({loss_type})\")\n",
    "    plt.ylabel(\"Loss\")\n",
    "    plt.xlabel(\"Epoch\")\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "if TRAIN_MODEL:\n",
    "    valid_losses = []\n",
    "    for epoch in range(1, EPOCHS + 1):\n",
    "        train(model, train_loader, optimizer, criterion, epoch)\n",
    "        valid_loss = evaluate(\n",
    "            model, valid_loader, criterion, verbose=True, type_loss=\"validation\"\n",
    "        )\n",
    "        valid_losses.append(valid_loss)\n",
    "        if valid_loss < best_loss:\n",
    "            best_loss = valid_loss\n",
    "            torch.save(model.state_dict(), \"model.pth\")\n",
    "        print(f\"Epoch: {epoch}\\tloss (validation): {valid_loss}\")\n",
    "\n",
    "\n",
    "# If model is saved, load it\n",
    "if os.path.exists(\"model.pth\"):\n",
    "    model.load_state_dict(torch.load(\"model.pth\"))\n",
    "\n",
    "\n",
    "if TRAIN_MODEL:\n",
    "    test_loss = evaluate(model, test_loader, criterion, verbose=True, type_loss=\"test\")\n",
    "    plotLosses(valid_losses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Sentence: @AmericanAir \n",
      "It's not what happens to us that matters...It's our response that matters. Way to drop the ball AA.\n",
      "True label: negative\n",
      "Prediction: negative   Proba: 0.9607663750648499\n",
      "\n",
      "Sentence: @AmericanAir Can't unload flight #3322 because jetway is broken.  #steps #planB? #waiting nearly an hour\n",
      "True label: negative\n",
      "Prediction: negative   Proba: 0.993521511554718\n",
      "\n",
      "Sentence: @AmericanAir If the flight I selected online was what was ticketed I would not be missing my connection. I need help getting to DFW or IAH!!\n",
      "True label: negative\n",
      "Prediction: negative   Proba: 0.9886950850486755\n",
      "\n",
      "Sentence: @AmericanAir I've been calling you for 3 straight days and no one picks up. Sure there are storms but there are also #customers Holler!\n",
      "True label: negative\n",
      "Prediction: negative   Proba: 0.9951163530349731\n",
      "\n",
      "Sentence: @AmericanAir No. I was told I got put on another flight and that I would get an email. Still haven't gotten one yet.\n",
      "True label: negative\n",
      "Prediction: negative   Proba: 0.9899234175682068\n",
      "\n",
      "Sentence: @AmericanAir i was spoken 2 like I'm an idiot and that is not OK!! I don't need to deal w/ that esp after the travel experience I've had\n",
      "True label: negative\n",
      "Prediction: negative   Proba: 0.9864535927772522\n",
      "\n",
      "Sentence: @AmericanAir now a delay to the rebooked flight?!\n",
      "True label: negative\n",
      "Prediction: negative   Proba: 0.989510715007782\n",
      "\n",
      "Sentence: @AmericanAir How are you going to compensate all of whose days/plans have been ruined because of the AA3490 delay/pending Cancelled Flightlation?\n",
      "True label: negative\n",
      "Prediction: negative   Proba: 0.9967429041862488\n",
      "\n",
      "Sentence: @AmericanAir what are my chances of making a connection to El Paso (AA504) with DFW from SAT (AA200) delayed 30 minutes?\n",
      "True label: negative\n",
      "Prediction: negative   Proba: 0.979961633682251\n",
      "\n",
      "Sentence: @AmericanAir they don't even give an option to hold.. Just say lines are busy Plz try Late Flightr\n",
      "True label: negative\n",
      "Prediction: negative   Proba: 0.9914728403091431\n",
      "\n",
      "Sentence: @AmericanAir there's an employee at gate 45 of JFK telling people their bag doesn't fit and needs to be checked when it clearly fits #AA291\n",
      "True label: negative\n",
      "Prediction: negative   Proba: 0.9900705218315125\n",
      "\n",
      "Sentence: @AmericanAir I love very much your planes, can you please follow me back? It's an amazing bussines!\n",
      "True label: positive\n",
      "Prediction: positive   Proba: 0.525505006313324\n",
      "\n",
      "Sentence: @AmericanAir Thanks for asking On second plane after maintenance issue, for flight from ORD to LIT. Sitting at gate in very very warm plane\n",
      "True label: negative\n",
      "Prediction: negative   Proba: 0.7036303877830505\n",
      "\n",
      "Sentence: @AmericanAir She was at gate on time though, they made her cry, and made a scene for 10 mins instead of boarding her. Plane still outside.\n",
      "True label: negative\n",
      "Prediction: negative   Proba: 0.947921633720398\n",
      "\n",
      "Sentence: @AmericanAir-everyone: its been weeks&amp;those dickheads @ AA hadn't contacted me...they lost my checked bag &amp; carryon and haven't offer to pay\n",
      "True label: negative\n",
      "Prediction: negative   Proba: 0.9580172896385193\n",
      "\n",
      "Sentence: @AmericanAir Oh, and losing my luggage #ridiculous # angrybird # where'smybag\n",
      "True label: negative\n",
      "Prediction: negative   Proba: 0.9251236915588379\n",
      "\n",
      "Sentence: @AmericanAir @usairways who is the next stop after customer service.\n",
      "True label: negative\n",
      "Prediction: negative   Proba: 0.9179588556289673\n",
      "\n",
      "Sentence: @AmericanAir ok makes no sense tho Since you'll give me a free upgrade to first.\n",
      "True label: negative\n",
      "Prediction: negative   Proba: 0.5149651765823364\n",
      "\n",
      "Sentence: @AmericanAir I was rebooked on a flight that was too Late Flight for my connection!\n",
      "True label: negative\n",
      "Prediction: negative   Proba: 0.9201931953430176\n",
      "\n",
      "Sentence: @AmericanAir @dfwairport Guys, let it go. http://t.co/vOxcghciJi\n",
      "True label: positive\n",
      "Prediction: positive   Proba: 0.6109899878501892\n"
     ]
    }
   ],
   "source": [
    "# Let's print the predictions of the model\n",
    "model.eval()\n",
    "model = model.to(device)\n",
    "with torch.no_grad():\n",
    "    for sentence, true_label in zip(data[\"test\"][\"sentence\"][100:130], data[\"test\"][\"label\"][60:80]):\n",
    "        tokenized_ = tokenizer(\n",
    "            sentence, truncation=True, padding=\"max_length\", max_length=T\n",
    "        )\n",
    "        input_ = torch.tensor(\n",
    "            [token2idx[token_id] for token_id in tokenized_[\"input_ids\"]]\n",
    "        ).unsqueeze(0)\n",
    "\n",
    "        causal_mask = torch.tensor(tokenized_[\"attention_mask\"])\n",
    "        input_, causal_mask = input_.to(device), causal_mask.to(device)\n",
    "        # if USE_CAUSAL_MASK:\n",
    "        output = model(input_, causal_mask)\n",
    "        # else:\n",
    "        #     output = model(input_)\n",
    "        pred = output.argmax(dim=1, keepdim=True)\n",
    "        print(\n",
    "            f\"\"\"\\nSentence: {sentence}\n",
    "True label: {inverse_target_map[pred.item()]}\n",
    "Prediction: {inverse_target_map[pred.item()]}   Proba: {output[0][pred.item()].item()}\"\"\"\n",
    "        )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Unit tests for transformer and attention\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TestTensorFunctions(unittest.TestCase):\n",
    "    def test_repeat(self):\n",
    "        x = torch.tensor([1, 2, 3])\n",
    "        n = 2\n",
    "        result = repeat(x, n)\n",
    "        expected = torch.tensor([[1, 2, 3], [1, 2, 3]])\n",
    "        self.assertTrue(torch.equal(result, expected))\n",
    "\n",
    "    def test_batched_matmul(self):\n",
    "        tensor_3d = torch.randn(10, 3, 4)\n",
    "        tensor_2d = torch.randn(4, 5)\n",
    "        result = batched_matmul(tensor_3d, tensor_2d)\n",
    "        expected = torch.bmm(tensor_3d, tensor_2d.unsqueeze(0).repeat((10, 1, 1)))\n",
    "        self.assertTrue(torch.allclose(result, expected))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "class EmbeddingLayerTest(unittest.TestCase):\n",
    "    def setUp(self):\n",
    "        # Set up your embedding layer or load your model\n",
    "        self.vocab_size = 10\n",
    "        self.d_model = 8\n",
    "        self.batch_size = 2\n",
    "        self.t = 4\n",
    "        self.model = Embedding(self.vocab_size, self.d_model)\n",
    "        self.criterion = nn.MSELoss()\n",
    "\n",
    "    def test_embedding_layer_forward(self):\n",
    "        # Define input tensor (batch_size=2, sequence_length=4)\n",
    "        x = torch.tensor([[1, 3, 5, 7], [0, 2, 4, 6]])\n",
    "\n",
    "        # Manually set model weights for the embedding matrix\n",
    "        self.model.embedding.data = torch.tensor(\n",
    "            [\n",
    "                [0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8],\n",
    "                [0.9, 1.0, 1.1, 1.2, 1.3, 1.4, 1.5, 1.6],\n",
    "                [1.7, 1.8, 1.9, 2.0, 2.1, 2.2, 2.3, 2.4],\n",
    "                [2.5, 2.6, 2.7, 2.8, 2.9, 3.0, 3.1, 3.2],\n",
    "                [3.3, 3.4, 3.5, 3.6, 3.7, 3.8, 3.9, 4.0],\n",
    "                [4.1, 4.2, 4.3, 4.4, 4.5, 4.6, 4.7, 4.8],\n",
    "                [4.9, 5.0, 5.1, 5.2, 5.3, 5.4, 5.5, 5.6],\n",
    "                [5.7, 5.8, 5.9, 6.0, 6.1, 6.2, 6.3, 6.4],\n",
    "                [6.5, 6.6, 6.7, 6.8, 6.9, 7.0, 7.1, 7.2],\n",
    "                [7.3, 7.4, 7.5, 7.6, 7.7, 7.8, 7.9, 8.0],\n",
    "            ]\n",
    "        )\n",
    "\n",
    "        # Calculate the expected output manually\n",
    "        expected_output = torch.tensor(\n",
    "            [\n",
    "                [\n",
    "                    [\n",
    "                        [0.9, 1.0, 1.1, 1.2, 1.3, 1.4, 1.5, 1.6],\n",
    "                        [2.5, 2.6, 2.7, 2.8, 2.9, 3.0, 3.1, 3.2],\n",
    "                        [4.1, 4.2, 4.3, 4.4, 4.5, 4.6, 4.7, 4.8],\n",
    "                        [5.7, 5.8, 5.9, 6.0, 6.1, 6.2, 6.3, 6.4],\n",
    "                    ],\n",
    "                    [\n",
    "                        [0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8],\n",
    "                        [1.7, 1.8, 1.9, 2.0, 2.1, 2.2, 2.3, 2.4],\n",
    "                        [3.3, 3.4, 3.5, 3.6, 3.7, 3.8, 3.9, 4.0],\n",
    "                        [4.9, 5.0, 5.1, 5.2, 5.3, 5.4, 5.5, 5.6],\n",
    "                    ],\n",
    "                ]\n",
    "            ]\n",
    "        )\n",
    "\n",
    "        # Check if the shape of the expected output matches\n",
    "        self.assertEqual(expected_output.shape, expected_output.shape)\n",
    "\n",
    "        # Check if the values of the expected output tensor match\n",
    "        self.assertTrue(torch.allclose(expected_output, expected_output, atol=1e-6))\n",
    "\n",
    "    def test_embedding_layer_loss(self):\n",
    "        # Define input tensors and target tensors\n",
    "        input_tensor = torch.randint(\n",
    "            0, self.vocab_size, (self.batch_size, self.t)\n",
    "        ).long()\n",
    "        target_tensor = torch.randn(self.batch_size, self.t, self.d_model)\n",
    "\n",
    "        # Forward pass through the embedding layer\n",
    "        output = self.model(input_tensor)\n",
    "\n",
    "        # Compute the loss\n",
    "        loss = self.criterion(output, target_tensor)\n",
    "\n",
    "        # Define an optimizer\n",
    "        optimizer = torch.optim.SGD(self.model.parameters(), lr=0.01)\n",
    "\n",
    "        # Save the parameters before the backward pass and parameter update\n",
    "        params_before = [param.clone() for param in self.model.parameters()]\n",
    "\n",
    "        # Backward pass\n",
    "        loss.backward()\n",
    "\n",
    "        # Update the parameters\n",
    "        optimizer.step()\n",
    "\n",
    "        # Check if the parameters have been updated\n",
    "        for param, param_before in zip(self.model.parameters(), params_before):\n",
    "            self.assertTrue(\n",
    "                torch.any(param.grad != 0), \"No gradients in the parameters\"\n",
    "            )\n",
    "            self.assertTrue(\n",
    "                torch.any(param != param_before), \"Parameters have not been updated\"\n",
    "            )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TestAttention(unittest.TestCase):\n",
    "    \"\"\"_summary_\n",
    "\n",
    "    Args:\n",
    "        unittest (_type_): unit test for a conjuntion linear layer\n",
    "            plus the attention block\n",
    "    \"\"\"\n",
    "\n",
    "\n",
    "class AttentionTest(unittest.TestCase):\n",
    "    def setUp(self):\n",
    "        self.batch_size = 2\n",
    "        self.d_k = 3\n",
    "        self.d_v = 3\n",
    "        self.T = 2\n",
    "        self.d_model = 4\n",
    "\n",
    "        # Set up your attention mechanism or load your model\n",
    "        self.model = Attention(self.d_k, self.d_v, self.d_model)\n",
    "        self.criterion = nn.MSELoss()\n",
    "\n",
    "    def test_attention_forward(self):\n",
    "        # Define input tensor (batch_size=2, sequence_length=2, d_model=4)\n",
    "        x = torch.tensor(\n",
    "            [\n",
    "                [[1.0, 2.0, 3.0, 4.0], [5.0, 6.0, 7.0, 8.0]],\n",
    "                [[9.0, 10.0, 11.0, 12.0], [13.0, 14.0, 15.0, 16.0]],\n",
    "            ]\n",
    "        )\n",
    "\n",
    "        # Manually set model weights for W_K, W_Q, and W_V\n",
    "        self.model.W_K.data = torch.tensor(\n",
    "            [[0.1, 0.2, 0.3], [0.4, 0.5, 0.6], [0.7, 0.8, 0.9], [1.0, 1.1, 1.2]],\n",
    "            dtype=torch.float32,\n",
    "        )\n",
    "        self.model.W_Q.data = torch.tensor(\n",
    "            [[1.2, 1.1, 1.0], [0.9, 0.8, 0.7], [0.6, 0.5, 0.4], [0.3, 0.2, 0.1]],\n",
    "            dtype=torch.float32,\n",
    "        )\n",
    "        self.model.W_V.data = torch.tensor(\n",
    "            [[0.5, 0.6, 0.7], [0.8, 0.9, 1.0], [1.1, 1.2, 1.3], [1.4, 1.5, 1.6]],\n",
    "            dtype=torch.float32,\n",
    "        )\n",
    "\n",
    "        # Expected output based on calculations from the attention mechanism\n",
    "        expected_output, _ = self.model(x)\n",
    "\n",
    "        # Calculate the expected output manually\n",
    "        # Calculate Q, K, and V using learned weights\n",
    "        Q = torch.matmul(x, self.model.W_Q)\n",
    "        K = torch.matmul(x, self.model.W_K)\n",
    "        V = torch.matmul(x, self.model.W_V)\n",
    "\n",
    "        # Calculate the attention scores\n",
    "        attention_scores = torch.matmul(Q, K.transpose(1, 2)) / (self.d_k**0.5)\n",
    "        attention_weights = torch.nn.functional.softmax(attention_scores, dim=-1)\n",
    "\n",
    "        # Apply attention weights to V to get the output\n",
    "        expected_output_manual = torch.matmul(attention_weights, V)\n",
    "\n",
    "        # Check if the shape of the expected output matches\n",
    "        self.assertEqual(expected_output.shape, expected_output_manual.shape)\n",
    "\n",
    "        # Check if the values of the expected output tensor match\n",
    "        self.assertTrue(\n",
    "            torch.allclose(expected_output, expected_output_manual, atol=1e-6)\n",
    "        )\n",
    "\n",
    "    def test_attention_loss(self):\n",
    "        # Test the loss function associated with the attention mechanism\n",
    "        # Define input tensors and target tensors\n",
    "\n",
    "        input_tensor = torch.rand(\n",
    "            (self.batch_size, self.T, self.d_model), requires_grad=True\n",
    "        )\n",
    "\n",
    "        # Forward pass through the attention mechanism\n",
    "        output, _ = self.model(input_tensor)\n",
    "\n",
    "        # Create dummy target tensor (replace with your actual target tensor)\n",
    "        target = torch.rand_like(output, requires_grad=False)\n",
    "\n",
    "        # Calculate the loss\n",
    "        loss = self.criterion(output, target)\n",
    "\n",
    "        # Define an optimizer\n",
    "        optimizer = torch.optim.SGD(self.model.parameters(), lr=0.01)\n",
    "\n",
    "        # Save the parameters before the backward pass and parameter update\n",
    "        params_before = [param.clone() for param in self.model.parameters()]\n",
    "\n",
    "        # Perform backward pass\n",
    "        loss.backward()\n",
    "\n",
    "        # Update the parameters\n",
    "        optimizer.step()\n",
    "\n",
    "        # Check if gradients are computed\n",
    "        self.assertTrue(\n",
    "            input_tensor.grad is not None, \"No gradients in the input tensor\"\n",
    "        )\n",
    "\n",
    "        # Check if the parameters have been updated\n",
    "        for param, param_before in zip(self.model.parameters(), params_before):\n",
    "            self.assertTrue(\n",
    "                torch.any(param != param_before), \"Parameters have not been updated\"\n",
    "            )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[159.9200, 174.0800, 188.2400, 202.4000],\n",
      "         [159.9200, 174.0800, 188.2400, 202.4000]],\n",
      "\n",
      "        [[344.5600, 375.0400, 405.5200, 436.0000],\n",
      "         [344.5600, 375.0400, 405.5200, 436.0000]]])\n"
     ]
    }
   ],
   "source": [
    "# Code by GPT4 to calculate the multihead attention output\n",
    "\n",
    "# Define the parameters\n",
    "d_k = 3\n",
    "d_v = 3\n",
    "d_model = 4\n",
    "h = 2\n",
    "batch_size = 2\n",
    "t = 2\n",
    "\n",
    "# Define the input tensor\n",
    "input_tensor = torch.tensor(\n",
    "    [\n",
    "        [[1.0, 2.0, 3.0, 4.0], [5.0, 6.0, 7.0, 8.0]],\n",
    "        [[9.0, 10.0, 11.0, 12.0], [13.0, 14.0, 15.0, 16.0]],\n",
    "    ],\n",
    "    dtype=torch.float32,\n",
    ")\n",
    "\n",
    "# Define the weights\n",
    "W_K = torch.tensor(\n",
    "    [[0.1, 0.2, 0.3], [0.4, 0.5, 0.6], [0.7, 0.8, 0.9], [1.0, 1.1, 1.2]],\n",
    "    dtype=torch.float32,\n",
    ")\n",
    "W_Q = torch.tensor(\n",
    "    [[0.2, 0.3, 0.4], [0.5, 0.6, 0.7], [0.8, 0.9, 1.0], [1.1, 1.2, 1.3]],\n",
    "    dtype=torch.float32,\n",
    ")\n",
    "W_V = torch.tensor(\n",
    "    [[0.3, 0.4, 0.5], [0.6, 0.7, 0.8], [0.9, 1.0, 1.1], [1.2, 1.3, 1.4]],\n",
    "    dtype=torch.float32,\n",
    ")\n",
    "W_O = torch.tensor(\n",
    "    [\n",
    "        [0.1, 0.2, 0.3, 0.4],\n",
    "        [0.5, 0.6, 0.7, 0.8],\n",
    "        [0.9, 1.0, 1.1, 1.2],\n",
    "        [1.3, 1.4, 1.5, 1.6],\n",
    "        [1.7, 1.8, 1.9, 2.0],\n",
    "        [2.1, 2.2, 2.3, 2.4],\n",
    "    ],\n",
    "    dtype=torch.float32,\n",
    ")\n",
    "\n",
    "# Initialize tensors for K, Q, V for each head\n",
    "Ks, Qs, Vs = [], [], []\n",
    "\n",
    "# Compute K, Q, V for each head\n",
    "for _ in range(h):\n",
    "    K = torch.matmul(input_tensor, W_K)\n",
    "    Q = torch.matmul(input_tensor, W_Q)\n",
    "    V = torch.matmul(input_tensor, W_V)\n",
    "    Ks.append(K)\n",
    "    Qs.append(Q)\n",
    "    Vs.append(V)\n",
    "\n",
    "# Initialize a tensor for the concatenated results\n",
    "concatenated_results = torch.zeros(batch_size, t, h * d_v)\n",
    "\n",
    "# Calculate the attention and concatenate results for each head\n",
    "for a_idx in range(h):\n",
    "    # Scaled dot product of Q and K\n",
    "    attention_scores = torch.matmul(Qs[a_idx], Ks[a_idx].transpose(-2, -1)) / (\n",
    "        d_k**0.5\n",
    "    )\n",
    "    attention_weights = torch.nn.functional.softmax(attention_scores, dim=-1)\n",
    "\n",
    "    # Weighted sum of V\n",
    "    head_output = torch.matmul(attention_weights, Vs[a_idx])\n",
    "\n",
    "    # Concatenate results\n",
    "    concatenated_results[:, :, a_idx * d_v : (a_idx + 1) * d_v] = head_output\n",
    "\n",
    "# Apply the final linear layer W_O\n",
    "expected_output = torch.matmul(concatenated_results, W_O)\n",
    "\n",
    "print(expected_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MultiHeadAttentionTest(unittest.TestCase):\n",
    "    @staticmethod\n",
    "    def calculate_expected_output(input_tensor, batch_size, t, h, d_k, d_v):\n",
    "        # Code by GPT4 to calculate the multihead attention output\n",
    "\n",
    "        # Define the weights\n",
    "        W_K = torch.tensor(\n",
    "            [[0.1, 0.2, 0.3], [0.4, 0.5, 0.6], [0.7, 0.8, 0.9], [1.0, 1.1, 1.2]],\n",
    "            dtype=torch.float32,\n",
    "        )\n",
    "        W_Q = torch.tensor(\n",
    "            [[0.2, 0.3, 0.4], [0.5, 0.6, 0.7], [0.8, 0.9, 1.0], [1.1, 1.2, 1.3]],\n",
    "            dtype=torch.float32,\n",
    "        )\n",
    "        W_V = torch.tensor(\n",
    "            [[0.3, 0.4, 0.5], [0.6, 0.7, 0.8], [0.9, 1.0, 1.1], [1.2, 1.3, 1.4]],\n",
    "            dtype=torch.float32,\n",
    "        )\n",
    "        W_O = torch.tensor(\n",
    "            [\n",
    "                [0.1, 0.2, 0.3, 0.4],\n",
    "                [0.5, 0.6, 0.7, 0.8],\n",
    "                [0.9, 1.0, 1.1, 1.2],\n",
    "                [1.3, 1.4, 1.5, 1.6],\n",
    "                [1.7, 1.8, 1.9, 2.0],\n",
    "                [2.1, 2.2, 2.3, 2.4],\n",
    "            ],\n",
    "            dtype=torch.float32,\n",
    "        )\n",
    "\n",
    "        # Initialize tensors for K, Q, V for each head\n",
    "        Ks, Qs, Vs = [], [], []\n",
    "\n",
    "        # Compute K, Q, V for each head\n",
    "        for _ in range(h):\n",
    "            K = torch.matmul(input_tensor, W_K)\n",
    "            Q = torch.matmul(input_tensor, W_Q)\n",
    "            V = torch.matmul(input_tensor, W_V)\n",
    "            Ks.append(K)\n",
    "            Qs.append(Q)\n",
    "            Vs.append(V)\n",
    "\n",
    "        # Initialize a tensor for the concatenated results\n",
    "        concatenated_results = torch.zeros(batch_size, t, h * d_v)\n",
    "\n",
    "        # Calculate the attention and concatenate results for each head\n",
    "        for a_idx in range(h):\n",
    "            # Scaled dot product of Q and K\n",
    "            attention_scores = torch.matmul(Qs[a_idx], Ks[a_idx].transpose(-2, -1)) / (\n",
    "                d_k**0.5\n",
    "            )\n",
    "            attention_weights = torch.nn.functional.softmax(attention_scores, dim=-1)\n",
    "\n",
    "            # Weighted sum of V\n",
    "            head_output = torch.matmul(attention_weights, Vs[a_idx])\n",
    "\n",
    "            # Concatenate results\n",
    "            concatenated_results[:, :, a_idx * d_v : (a_idx + 1) * d_v] = head_output\n",
    "\n",
    "        # Apply the final linear layer W_O\n",
    "        expected_output = torch.matmul(concatenated_results, W_O)\n",
    "\n",
    "        return expected_output\n",
    "    \n",
    "    def setUp(self):\n",
    "        self.h = 2\n",
    "        self.d_k = 3\n",
    "        self.d_v = 3\n",
    "        self.d_model = 4\n",
    "        self.batch_size = 2\n",
    "        self.t = 2\n",
    "        \n",
    "        # Initialize the multi-head attention model\n",
    "        self.model = MultiHeadAttention(h=self.h, d_K=self.d_k, d_V=self.d_v, d_model=self.d_model)\n",
    "        self.criterion = nn.MSELoss()\n",
    "\n",
    "        # Manually setting the weights for the test\n",
    "        for head in self.model.attentions:\n",
    "            # These weights should be carefully chosen to ensure a predictable output\n",
    "            head.W_K = nn.Parameter(\n",
    "                torch.tensor(\n",
    "                    [[0.1, 0.2, 0.3], [0.4, 0.5, 0.6], [0.7, 0.8, 0.9], [1.0, 1.1, 1.2]]\n",
    "                )\n",
    "            )\n",
    "            head.W_Q = nn.Parameter(\n",
    "                torch.tensor(\n",
    "                    [[0.2, 0.3, 0.4], [0.5, 0.6, 0.7], [0.8, 0.9, 1.0], [1.1, 1.2, 1.3]]\n",
    "                )\n",
    "            )\n",
    "            head.W_V = nn.Parameter(\n",
    "                torch.tensor(\n",
    "                    [[0.3, 0.4, 0.5], [0.6, 0.7, 0.8], [0.9, 1.0, 1.1], [1.2, 1.3, 1.4]]\n",
    "                )\n",
    "            )\n",
    "\n",
    "        # Output linear layer weights\n",
    "        self.model.W_O = nn.Parameter(\n",
    "            torch.tensor(\n",
    "                [\n",
    "                    [0.1, 0.2, 0.3, 0.4],\n",
    "                    [0.5, 0.6, 0.7, 0.8],\n",
    "                    [0.9, 1.0, 1.1, 1.2],\n",
    "                    [1.3, 1.4, 1.5, 1.6],\n",
    "                    [1.7, 1.8, 1.9, 2.0],\n",
    "                    [2.1, 2.2, 2.3, 2.4],\n",
    "                ],\n",
    "                dtype=torch.float32,\n",
    "            )\n",
    "        )\n",
    "\n",
    "        # Shape of W_O, according to the paper \"Attention Is All You Need\"\n",
    "        self.assertEqual(list(self.model.W_O.shape), [self.h * self.d_v, self.d_model])\n",
    "\n",
    "    def test_multi_head_attention_forward(self):\n",
    "        # Define a specific input tensor (batch_size, t, d_model)\n",
    "        input_tensor = torch.tensor(\n",
    "            [\n",
    "                [[1.0, 2.0, 3.0, 4.0], [5.0, 6.0, 7.0, 8.0]],\n",
    "                [[9.0, 10.0, 11.0, 12.0], [13.0, 14.0, 15.0, 16.0]],\n",
    "            ]\n",
    "        )\n",
    "\n",
    "        # Expected output tensor based on the input and the model weights\n",
    "        # This tensor should be calculated manually based on the model's operations\n",
    "        expected_output = self.calculate_expected_output(\n",
    "            input_tensor, self.batch_size, self.t, self.h, self.d_k, self.d_v\n",
    "        )\n",
    "\n",
    "        # Run the forward pass\n",
    "        output, _ = self.model(input_tensor)\n",
    "\n",
    "        # Check the shape of the output tensor\n",
    "        self.assertEqual(output.shape, (self.batch_size, self.t, self.d_model))\n",
    "\n",
    "        # Check the values of the output tensor\n",
    "        self.assertTrue(torch.allclose(output, expected_output, atol=1e-4))\n",
    "\n",
    "    def test_multi_head_attention_loss(self):\n",
    "        # Test the loss function associated with the multi-head attention mechanism\n",
    "        # Define input tensors and target tensors\n",
    "\n",
    "        input_tensor = torch.rand(\n",
    "            (self.batch_size, self.t, self.d_model), requires_grad=True\n",
    "        )\n",
    "\n",
    "        # Forward pass through the multi-head attention mechanism\n",
    "        output, _ = self.model(input_tensor)\n",
    "\n",
    "        # Create dummy target tensor (replace with your actual target tensor)\n",
    "        target = torch.rand_like(output, requires_grad=False)\n",
    "\n",
    "        # Calculate the loss\n",
    "        loss = self.criterion(output, target)\n",
    "\n",
    "        # Define an optimizer\n",
    "        optimizer = torch.optim.SGD(self.model.parameters(), lr=0.01)\n",
    "\n",
    "        # Save the parameters before the backward pass and parameter update\n",
    "        params_before = [param.clone() for param in self.model.parameters()]\n",
    "\n",
    "        # Perform backward pass\n",
    "        loss.backward()\n",
    "\n",
    "        # Update the parameters\n",
    "        optimizer.step()\n",
    "\n",
    "        # Check if gradients are computed\n",
    "        self.assertTrue(\n",
    "            input_tensor.grad is not None, \"No gradients in the input tensor\"\n",
    "        )\n",
    "\n",
    "        # Check if the parameters have been updated\n",
    "        for param, param_before in zip(self.model.parameters(), params_before):\n",
    "            self.assertTrue(\n",
    "                torch.any(param != param_before), \"Parameters have not been updated\"\n",
    "            )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_expected_output(x, attentions, W_O):\n",
    "    batch_size, T, d_model = x.shape\n",
    "    h = len(attentions)\n",
    "    d_k, d_v = attentions[0].W_K.shape[1], attentions[0].W_V.shape[1]\n",
    "\n",
    "    # Initialize the tensor to hold the concatenated outputs from each head\n",
    "    concatenated_heads = torch.zeros((batch_size, T, h * d_v))\n",
    "\n",
    "    for i in range(h):\n",
    "        W_K, W_Q, W_V = attentions[i].W_K, attentions[i].W_Q, attentions[i].W_V\n",
    "\n",
    "        # Calculate K, Q, V matrices\n",
    "        K = x @ W_K\n",
    "        Q = x @ W_Q\n",
    "        V = x @ W_V\n",
    "\n",
    "        # Calculate attention scores and apply softmax (simplified here)\n",
    "        attention_scores = (Q @ K.transpose(-2, -1)) / (d_k**0.5)\n",
    "        # In a real scenario, apply softmax to attention_scores here\n",
    "\n",
    "        # Calculate the weighted sum of V\n",
    "        weighted_sum = attention_scores @ V\n",
    "\n",
    "        # Concatenate results from each head\n",
    "        concatenated_heads[:, :, i * d_v : (i + 1) * d_v] = weighted_sum\n",
    "\n",
    "    # Multiply with W_O\n",
    "    expected_output = concatenated_heads @ W_O\n",
    "    return expected_output\n",
    "\n",
    "\n",
    "class TransformerBlockTest(unittest.TestCase):\n",
    "    def calculate_attention_output(self, x, W_K, W_Q, W_V, d_k):\n",
    "        \"\"\"\n",
    "        Calculate the output of a single head attention.\n",
    "        \"\"\"\n",
    "        K = x @ W_K\n",
    "        Q = x @ W_Q\n",
    "        V = x @ W_V\n",
    "\n",
    "        attention_scores = (Q @ K.transpose(-2, -1)) / (d_k**0.5)\n",
    "        attention_scores = F.softmax(attention_scores, dim=-1)\n",
    "        attention_output = attention_scores @ V\n",
    "\n",
    "        return attention_output\n",
    "\n",
    "    def calculate_expected_output(\n",
    "        self, x, W_Ks, W_Qs, W_Vs, W_O, linear_weights, linear_biases\n",
    "    ):\n",
    "        \"\"\"\n",
    "        Calculate the expected output of the TransformerBlock.\n",
    "        \"\"\"\n",
    "        batch_size, T, d_model = x.shape\n",
    "        h = len(W_Ks)\n",
    "        d_k, d_v = W_Ks[0].shape[1], W_Vs[0].shape[1]\n",
    "\n",
    "        # Step 1: Multi-head attention\n",
    "        concatenated_heads = torch.zeros((batch_size, T, h * d_v))\n",
    "        for i in range(h):\n",
    "            attention_output = self.calculate_attention_output(\n",
    "                x, W_Ks[i], W_Qs[i], W_Vs[i], d_k\n",
    "            )\n",
    "            concatenated_heads[:, :, i * d_v : (i + 1) * d_v] = attention_output\n",
    "\n",
    "        multihead_output = concatenated_heads @ W_O\n",
    "\n",
    "        # Step 2: Apply LayerNorm (simplified version)\n",
    "        norm_output = F.layer_norm(multihead_output, multihead_output.shape[1:])\n",
    "\n",
    "        # Step 3: ANN layers (assuming two linear layers with ReLU and Dropout in between)\n",
    "        ann_output = F.linear(norm_output, linear_weights[0], linear_biases[0])\n",
    "        ann_output = F.dropout(ann_output, p=0.1)\n",
    "        ann_output = F.relu(ann_output)\n",
    "        ann_output = F.linear(ann_output, linear_weights[1], linear_biases[1])\n",
    "\n",
    "        return ann_output\n",
    "\n",
    "    def setUp(self):\n",
    "        self.batch_size = 2\n",
    "        self.d_k = 3\n",
    "        self.d_v = 3\n",
    "        self.t = 4\n",
    "        self.d_model = 3\n",
    "        self.h = 2\n",
    "        # Set up your Transformer block model\n",
    "        self.model = TransformerBlock(\n",
    "            d_K=self.d_k, d_V=self.d_v, d_model=self.d_model, h=self.h\n",
    "        )\n",
    "        self.criterion = nn.MSELoss()\n",
    "\n",
    "\n",
    "def test_transformer_block_forward(self):\n",
    "    # Define the input tensor\n",
    "    x = torch.tensor(\n",
    "        [\n",
    "            [[1.0, 2.0, 3.0], [4.0, 5.0, 6.0], [7.0, 8.0, 9.0], [10.0, 11.0, 12.0]],\n",
    "            [\n",
    "                [13.0, 14.0, 15.0],\n",
    "                [16.0, 17.0, 18.0],\n",
    "                [19.0, 20.0, 21.0],\n",
    "                [22.0, 23.0, 24.0],\n",
    "            ],\n",
    "        ]\n",
    "    )\n",
    "\n",
    "    # Manually set and collect the weights for each Attention layer\n",
    "    W_Ks = []\n",
    "    W_Qs = []\n",
    "    W_Vs = []\n",
    "    for i, attention in enumerate(self.model.mha.attentions):\n",
    "        W_K = torch.tensor(\n",
    "            [\n",
    "                [0.1 * (i + 1), 0.2 * (i + 1), 0.3 * (i + 1)],\n",
    "                [0.4 * (i + 1), 0.5 * (i + 1), 0.6 * (i + 1)],\n",
    "                [0.7 * (i + 1), 0.8 * (i + 1), 0.9 * (i + 1)],\n",
    "            ]\n",
    "        )\n",
    "        W_Q = torch.tensor(\n",
    "            [\n",
    "                [0.9 * (i + 1), 0.8 * (i + 1), 0.7 * (i + 1)],\n",
    "                [0.6 * (i + 1), 0.5 * (i + 1), 0.4 * (i + 1)],\n",
    "                [0.3 * (i + 1), 0.2 * (i + 1), 0.1 * (i + 1)],\n",
    "            ]\n",
    "        )\n",
    "        W_V = torch.tensor(\n",
    "            [\n",
    "                [0.1 * (i + 1), 0.1 * (i + 1), 0.1 * (i + 1)],\n",
    "                [0.2 * (i + 1), 0.2 * (i + 1), 0.2 * (i + 1)],\n",
    "                [0.3 * (i + 1), 0.3 * (i + 1), 0.3 * (i + 1)],\n",
    "            ]\n",
    "        )\n",
    "        attention.W_K.data = W_K\n",
    "        attention.W_Q.data = W_Q\n",
    "        attention.W_V.data = W_V\n",
    "        W_Ks.append(W_K)\n",
    "        W_Qs.append(W_Q)\n",
    "        W_Vs.append(W_V)\n",
    "\n",
    "    # Set and collect weights for W_O in MultiHeadAttention\n",
    "    W_O = torch.tensor(\n",
    "        [\n",
    "            [0.1, 0.2, 0.3],\n",
    "            [0.4, 0.5, 0.6],\n",
    "            [0.7, 0.8, 0.9],\n",
    "            [0.9, 0.8, 0.7],\n",
    "            [0.6, 0.5, 0.4],\n",
    "            [0.3, 0.2, 0.1],\n",
    "        ]\n",
    "    )\n",
    "    self.model.mha.W_O.data = W_O\n",
    "\n",
    "    # Collect weights and biases for ANN layers (Assuming two linear layers)\n",
    "    linear_weights = [self.model.ann[0].weight, self.model.ann[3].weight]\n",
    "    linear_biases = [self.model.ann[0].bias, self.model.ann[3].bias]\n",
    "\n",
    "    # Calculate the expected output tensor\n",
    "    expected_output = self.calculate_expected_output(\n",
    "        x, W_Ks, W_Qs, W_Vs, W_O, linear_weights, linear_biases\n",
    "    )\n",
    "\n",
    "    # Forward pass\n",
    "    output, _ = self.model(x)\n",
    "\n",
    "    # Check the shape of the output tensor\n",
    "    self.assertEqual(output.shape, expected_output.shape)\n",
    "\n",
    "    # Check the values of the output tensor\n",
    "    self.assertTrue(torch.allclose(output, expected_output, atol=1e-6))\n",
    "\n",
    "    def test_transformer_block_loss(self):\n",
    "        # Test the loss function associated with the Transformer block\n",
    "        # Define input tensors and target tensors\n",
    "\n",
    "        input_tensor = torch.rand(\n",
    "            (self.batch_size, self.t, self.d_model), requires_grad=True\n",
    "        )\n",
    "\n",
    "        # Forward pass through the Transformer block\n",
    "        output = self.model(input_tensor)\n",
    "\n",
    "        # Create dummy target tensor (replace with your actual target tensor)\n",
    "        target = torch.rand_like(output, requires_grad=False)\n",
    "\n",
    "        # Calculate the loss\n",
    "        loss = self.criterion(output, target)\n",
    "\n",
    "        # Define an optimizer\n",
    "        optimizer = torch.optim.SGD(self.model.parameters(), lr=0.01)\n",
    "\n",
    "        # Save the parameters before the backward pass and parameter update\n",
    "        params_before = [param.clone() for param in self.model.parameters()]\n",
    "\n",
    "        # Perform backward pass\n",
    "        loss.backward()\n",
    "\n",
    "        # Update the parameters\n",
    "        optimizer.step()\n",
    "\n",
    "        # Check if gradients are computed\n",
    "        self.assertTrue(\n",
    "            input_tensor.grad is not None, \"No gradients in the input tensor\"\n",
    "        )\n",
    "\n",
    "        # Check if the parameters have been updated\n",
    "        for param, param_before in zip(self.model.parameters(), params_before):\n",
    "            self.assertTrue(\n",
    "                torch.any(param != param_before), \"Parameters have not been updated\"\n",
    "            )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0, 1, 2,  ..., 7, 8, 9],\n",
       "        [9, 0, 1,  ..., 6, 7, 8],\n",
       "        [8, 9, 0,  ..., 5, 6, 7],\n",
       "        ...,\n",
       "        [5, 6, 7,  ..., 2, 3, 4],\n",
       "        [4, 5, 6,  ..., 1, 2, 3],\n",
       "        [3, 4, 5,  ..., 0, 1, 2]])"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def getTestX(batch_size=BATCH_SIZE, t=T, vocab_size=VOCAB_SIZE):\n",
    "    x = torch.arange(start=0, end=batch_size * t).reshape(batch_size, t) % vocab_size\n",
    "\n",
    "    # each row (wor of index i) of x must be translocated by i positions\n",
    "    for i in range(batch_size):\n",
    "        x[i] = torch.roll(x[i], i)\n",
    "    return x\n",
    "\n",
    "\n",
    "getTestX()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scaled_dot_product_attention(Q, K, V):\n",
    "    matmul_qk = torch.matmul(Q, K.transpose(-2, -1))  # Scaled QK^T\n",
    "    d_k = Q.size(-1)\n",
    "    scaled_attention_logits = matmul_qk / math.sqrt(d_k)\n",
    "    attention_weights = F.softmax(\n",
    "        scaled_attention_logits, dim=-1\n",
    "    )  # Softmax over last axis (seq_len_k)\n",
    "    output = torch.matmul(attention_weights, V)  # Softmax(QK^T)V\n",
    "    return output\n",
    "\n",
    "\n",
    "def calculate_expected_output(x, model):\n",
    "    \"\"\"This function must calculate the expected output of the model, given the input x.\n",
    "    This function must not forward pass the model, but rather calculate the expected output\n",
    "    The expected output is function of the weights of the model, which are defined in the test_forward method\n",
    "    of the ClassifierEncoderTest class.\n",
    "    This function must follow the \"Attention is all you need\" paper.\n",
    "\n",
    "    Args:\n",
    "        x (torch.Tensor): Input tensor of shape (batch, T)\n",
    "        model (_type_): _description_\n",
    "    \"\"\"\n",
    "    batch_size = x.shape[0]\n",
    "    t = x.shape[1]\n",
    "\n",
    "    embedded_x = model.embedding(x)\n",
    "\n",
    "    # Health checking forward: assert model forward equals simulated forward\n",
    "    assert torch.allclose(embedded_x, model.embedding(x))\n",
    "\n",
    "    def positional_encoding(max_len, d_model):\n",
    "        pe = torch.zeros(max_len, d_model)\n",
    "        position = torch.arange(0, max_len, dtype=torch.float).unsqueeze(1)\n",
    "        div_term = torch.exp(\n",
    "            torch.arange(0, d_model, 2).float() * (-math.log(10000.0) / d_model)\n",
    "        )\n",
    "        div_term = div_term.unsqueeze(0)\n",
    "\n",
    "        for i in range(max_len):\n",
    "            for j in range(0, d_model, 2):\n",
    "                pe[i, j] = torch.sin(position[i] * div_term[0, j // 2])\n",
    "                if j + 1 < d_model:\n",
    "                    pe[i, j + 1] = torch.cos(position[i] * div_term[0, j // 2])\n",
    "\n",
    "        return pe.unsqueeze(0).repeat(batch_size, 1, 1)\n",
    "\n",
    "    position_encoding = positional_encoding(t, model.d_model)\n",
    "    assert position_encoding.shape == (batch_size, t, model.d_model)\n",
    "\n",
    "    # Health checking forward: assert model forward equals simulated forward\n",
    "    assert torch.allclose(position_encoding, model.position_encoding)\n",
    "\n",
    "    transformer_input = embedded_x + position_encoding\n",
    "\n",
    "    # Health checking forward: assert model forward equals simulated forward\n",
    "    assert torch.allclose(\n",
    "        transformer_input, model.embedding(x) + model.position_encoding\n",
    "    )\n",
    "\n",
    "    # Transformer Blocks\n",
    "    for block in model.transformer_blocks:\n",
    "        # Multi-Head Attention\n",
    "        mha_output = torch.zeros_like(transformer_input)\n",
    "        assert mha_output.shape == (batch_size, t, model.d_model)\n",
    "        head_outputs = torch.zeros((batch_size, t, model.d_V * model.h))\n",
    "        for head_idx, head in enumerate(block.mha.attentions):\n",
    "            Q = batched_matmul(transformer_input, head.W_Q)\n",
    "            K = batched_matmul(transformer_input, head.W_K)\n",
    "            V = batched_matmul(transformer_input, head.W_V)\n",
    "            head_output = scaled_dot_product_attention(Q, K, V)\n",
    "\n",
    "            # health checking forward: assert model forward equals simulated forward\n",
    "            assert torch.allclose(head_output, head.forward(transformer_input)[0])\n",
    "\n",
    "            # Assert the shape of the output of the head,\n",
    "            # bases on the \"Attention is all you need\" paper\n",
    "            assert head_output.shape == (batch_size, t, model.d_V)\n",
    "\n",
    "            head_outputs[\n",
    "                :, :, model.d_V * head_idx : model.d_V * (head_idx + 1)\n",
    "            ] = head_output\n",
    "\n",
    "        mha_output += batched_matmul(head_outputs, block.mha.W_O)\n",
    "\n",
    "        # Health checking forward: assert model forward equals simulated forward\n",
    "        assert torch.allclose(mha_output, block.mha(transformer_input)[0])\n",
    "\n",
    "        # Layer Normalization\n",
    "        normed_mha_output = block.layer_norm(\n",
    "            mha_output + transformer_input\n",
    "        )  # Assuming residual connection\n",
    "\n",
    "        # Health checking forward: assert model forward equals simulated forward\n",
    "        assert torch.allclose(\n",
    "            normed_mha_output,\n",
    "            block.layer_norm(block.mha(transformer_input)[0] + transformer_input),\n",
    "        )\n",
    "\n",
    "        # Do it now...\n",
    "        # 1. Linear\n",
    "        ann_output = (\n",
    "            torch.matmul(normed_mha_output, block.ann[0].weight.T) + block.ann[0].bias\n",
    "        )\n",
    "        assert ann_output.shape == (batch_size, t, model.d_model)\n",
    "\n",
    "        # Health checking forward: assert model forward equals simulated forward\n",
    "        assert torch.allclose(ann_output, block.ann[0](normed_mha_output))\n",
    "\n",
    "        # 2. Dropout\n",
    "        # ann_output = block.ann[1](ann_output)\n",
    "        # assert ann_output.shape == (batch_size, t, model.d_model)\n",
    "\n",
    "        # 3. ReLU\n",
    "        ann_output_relu = F.relu(ann_output)\n",
    "        assert ann_output_relu.shape == (batch_size, t, model.d_model)\n",
    "\n",
    "        # Health checking forward: assert model forward equals simulated forward\n",
    "        assert torch.allclose(ann_output_relu, block.ann[2](ann_output))\n",
    "\n",
    "        # 4. Linear\n",
    "        ann_output_linear_2 = (\n",
    "            torch.matmul(ann_output_relu, block.ann[3].weight.T) + block.ann[3].bias\n",
    "        )\n",
    "        assert ann_output_linear_2.shape == (batch_size, t, model.d_model)\n",
    "\n",
    "        # Health checking forward: assert model forward equals simulated forward\n",
    "        assert torch.allclose(ann_output_linear_2, block.ann[3](ann_output_relu))\n",
    "\n",
    "        # 5. Dropout\n",
    "        # ann_output_linear_2 = block.ann[4](ann_output_linear_2)\n",
    "        # assert ann_output_linear_2.shape == (batch_size, t, model.d_model)\n",
    "\n",
    "        # Layer Normalization\n",
    "        normed_ann_output_linear_2 = block.layer_norm(\n",
    "            ann_output_linear_2 + normed_mha_output\n",
    "        )\n",
    "\n",
    "        # Health checking forward: assert model forward equals simulated forward\n",
    "        assert torch.allclose(\n",
    "            normed_ann_output_linear_2,\n",
    "            block.layer_norm(ann_output_linear_2 + normed_mha_output),\n",
    "        )\n",
    "\n",
    "        # Prepare for next block\n",
    "        transformer_input = normed_ann_output_linear_2\n",
    "\n",
    "    # Prediction Head\n",
    "\n",
    "    # 1. Linear\n",
    "    output_linear = (\n",
    "        torch.matmul(transformer_input, model.prediction_head.weight.T)\n",
    "        + model.prediction_head.bias\n",
    "    )\n",
    "    assert output_linear.shape == (batch_size, t, model.n_classes)\n",
    "\n",
    "    # Health checking forward: assert model forward equals simulated forward\n",
    "    assert torch.allclose(output_linear, model.prediction_head(transformer_input))\n",
    "\n",
    "    # 2. Dropout\n",
    "    # final_output = model.prediction_head[1](final_output)\n",
    "    # assert final_output.shape == (batch_size, t, model.n_classes)\n",
    "\n",
    "    # 3. Softmax\n",
    "    final_output = nn.Softmax(dim=-1)(output_linear)\n",
    "\n",
    "    # return only the last value of the sequence\n",
    "    final_output = final_output[:, -1, :]\n",
    "\n",
    "    # Health checking forward: assert model forward equals simulated forward\n",
    "    assert torch.allclose(\n",
    "        final_output,\n",
    "        F.softmax(model.prediction_head(transformer_input), dim=-1)[:, -1, :],\n",
    "    )\n",
    "\n",
    "    return final_output\n",
    "\n",
    "\n",
    "# Lets make unit test for ClassiofierEncoder\n",
    "class ClassifierEncoderTest(unittest.TestCase):\n",
    "    def setUp(self):\n",
    "        self.batch_size = 3\n",
    "        self.d_k = 3\n",
    "        self.d_v = 3\n",
    "        self.t = 4\n",
    "        self.d_model = 3\n",
    "        self.h = 2\n",
    "        self.t_blocks = 2\n",
    "        self.vocab_size = 6\n",
    "\n",
    "        self.model = ClassifierEncoder(\n",
    "            t=self.t,\n",
    "            d_K=self.d_k,\n",
    "            d_V=self.d_v,\n",
    "            d_model=self.d_model,\n",
    "            h=self.h,\n",
    "            vocab_size=self.vocab_size,\n",
    "            n_transformers=self.t_blocks,\n",
    "            n_classes=N_CLASSES,\n",
    "        )\n",
    "        self.criterion = nn.MSELoss()\n",
    "\n",
    "    def test_forward(self):\n",
    "        # Create a random input\n",
    "        x = getTestX(self.batch_size, self.t, self.vocab_size)\n",
    "\n",
    "        # define the weights of the model\n",
    "        with torch.no_grad():\n",
    "            # 1. define weights for the embedding layer\n",
    "            self.model.embedding.embedding = nn.Parameter(\n",
    "                torch.tensor(\n",
    "                    [\n",
    "                        [0.1, 0.05, 0.02],\n",
    "                        [0.03, 0.07, 0.01],\n",
    "                        [0.04, 0.02, 0.08],\n",
    "                        [0.06, 0.03, 0.09],\n",
    "                        [0.02, 0.06, 0.04],\n",
    "                        [0.05, 0.01, 0.07],\n",
    "                    ]\n",
    "                )\n",
    "            )\n",
    "            # assert embedding has shape (vocab_size, d_model)\n",
    "            self.assertEqual(\n",
    "                self.model.embedding.embedding.shape,\n",
    "                torch.Size((self.vocab_size, self.d_model)),\n",
    "            )\n",
    "\n",
    "            # 2. define weights for the transformer blocks\n",
    "\n",
    "            # 2.1. define weights for the multihead attention layers\n",
    "            for t_idx in range(self.t_blocks):\n",
    "                for a_idx in range(self.h):\n",
    "                    self.model.transformer_blocks[t_idx].mha.attentions[\n",
    "                        a_idx\n",
    "                    ].W_Q = nn.Parameter(\n",
    "                        torch.tensor(\n",
    "                            [[0.1, 0.05, 0.02], [0.03, 0.07, 0.01], [0.04, 0.02, 0.08]]\n",
    "                        )\n",
    "                    )\n",
    "                    self.model.transformer_blocks[t_idx].mha.attentions[\n",
    "                        a_idx\n",
    "                    ].W_K = nn.Parameter(\n",
    "                        torch.tensor(\n",
    "                            [[0.06, 0.03, 0.09], [0.02, 0.08, 0.01], [0.07, 0.01, 0.04]]\n",
    "                        )\n",
    "                    )\n",
    "                    self.model.transformer_blocks[t_idx].mha.attentions[\n",
    "                        a_idx\n",
    "                    ].W_V = nn.Parameter(\n",
    "                        torch.tensor(\n",
    "                            [[0.05, 0.02, 0.1], [0.08, 0.01, 0.03], [0.01, 0.04, 0.07]]\n",
    "                        )\n",
    "                    )\n",
    "\n",
    "                # 2.2. define weights for the ANN layers\n",
    "                self.model.transformer_blocks[t_idx].ann[0].weight = nn.Parameter(\n",
    "                    torch.tensor(\n",
    "                        [\n",
    "                            [0.1, 0.05, 0.02],\n",
    "                            [0.03, 0.07, 0.01],\n",
    "                            [0.04, 0.02, 0.08],\n",
    "                        ]\n",
    "                    )\n",
    "                )\n",
    "                self.model.transformer_blocks[t_idx].ann[0].bias = nn.Parameter(\n",
    "                    torch.tensor([0.1, 0.05, 0.02])\n",
    "                )\n",
    "                self.model.transformer_blocks[t_idx].ann[3].weight = nn.Parameter(\n",
    "                    torch.tensor(\n",
    "                        [\n",
    "                            [0.1, 0.05, 0.02],\n",
    "                            [0.03, 0.07, 0.01],\n",
    "                            [0.04, 0.02, 0.08],\n",
    "                        ]\n",
    "                    )\n",
    "                )\n",
    "                self.model.transformer_blocks[t_idx].ann[3].bias = nn.Parameter(\n",
    "                    torch.tensor([0.1, 0.05, 0.02])\n",
    "                )\n",
    "\n",
    "                # 2.3. define weights for the W_O\n",
    "                # W_O must have shape (h * d_V, d_model)\n",
    "                self.model.transformer_blocks[t_idx].mha.W_O = nn.Parameter(\n",
    "                    torch.tensor(\n",
    "                        [\n",
    "                            [0.1, 0.05, 0.02],\n",
    "                            [0.03, 0.07, 0.01],\n",
    "                            [0.04, 0.02, 0.08],\n",
    "                            [0.06, 0.03, 0.09],\n",
    "                            [0.02, 0.08, 0.01],\n",
    "                            [0.07, 0.01, 0.04],\n",
    "                        ]\n",
    "                    )\n",
    "                )\n",
    "\n",
    "                # assert W_O has shape (h * d_V, d_model)\n",
    "                self.assertEqual(\n",
    "                    self.model.transformer_blocks[t_idx].mha.W_O.shape,\n",
    "                    torch.Size((self.h * self.d_v, self.d_model)),\n",
    "                )\n",
    "\n",
    "            # Now that wights are defined, let's in fact unittest the forward pass of the ClassifierEncoder\n",
    "            self.model = self.model\n",
    "            self.model.eval()\n",
    "            out = self.model(x)\n",
    "\n",
    "            # 1. test the shape of the output\n",
    "            self.assertEqual(out.shape, torch.Size((self.batch_size, N_CLASSES)))\n",
    "\n",
    "            # 2. test the values of the output\n",
    "            expected_output = calculate_expected_output(x, self.model)\n",
    "\n",
    "            self.assertTrue(torch.allclose(out, expected_output, atol=1e-3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "EEE..EE..\n",
      "======================================================================\n",
      "ERROR: test_attention_forward (__main__.AttentionTest)\n",
      "----------------------------------------------------------------------\n",
      "Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_61725/2637871889.py\", line 46, in test_attention_forward\n",
      "    expected_output, _ = self.model(x)\n",
      "  File \"/home/bruno/anaconda3/envs/gpt/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1501, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "  File \"/tmp/ipykernel_61725/4253325660.py\", line 48, in forward\n",
      "    attention_scores = attention_scores.masked_fill(self.causal_mask == 0, -np.inf)\n",
      "RuntimeError: The size of tensor a (80) must match the size of tensor b (2) at non-singleton dimension 2\n",
      "\n",
      "======================================================================\n",
      "ERROR: test_attention_loss (__main__.AttentionTest)\n",
      "----------------------------------------------------------------------\n",
      "Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_61725/2637871889.py\", line 78, in test_attention_loss\n",
      "    output, _ = self.model(input_tensor)\n",
      "  File \"/home/bruno/anaconda3/envs/gpt/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1501, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "  File \"/tmp/ipykernel_61725/4253325660.py\", line 48, in forward\n",
      "    attention_scores = attention_scores.masked_fill(self.causal_mask == 0, -np.inf)\n",
      "RuntimeError: The size of tensor a (80) must match the size of tensor b (2) at non-singleton dimension 2\n",
      "\n",
      "======================================================================\n",
      "ERROR: test_forward (__main__.ClassifierEncoderTest)\n",
      "----------------------------------------------------------------------\n",
      "Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_61725/1261332530.py\", line 304, in test_forward\n",
      "    out = self.model(x)\n",
      "  File \"/home/bruno/anaconda3/envs/gpt/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1501, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "  File \"/tmp/ipykernel_61725/411513722.py\", line 39, in forward\n",
      "    x = super().forward(x, pad_mask)\n",
      "  File \"/tmp/ipykernel_61725/4274056326.py\", line 39, in forward\n",
      "    x = block(x)\n",
      "  File \"/home/bruno/anaconda3/envs/gpt/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1501, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "  File \"/tmp/ipykernel_61725/2593639343.py\", line 18, in forward\n",
      "    x = self.layer_norm(x + self.mha(x, pad_mask)[0])\n",
      "  File \"/home/bruno/anaconda3/envs/gpt/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1501, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "  File \"/tmp/ipykernel_61725/815712447.py\", line 20, in forward\n",
      "    attention_results = [attention(x, pad_mask)[0] for attention in self.attentions]\n",
      "  File \"/tmp/ipykernel_61725/815712447.py\", line 20, in <listcomp>\n",
      "    attention_results = [attention(x, pad_mask)[0] for attention in self.attentions]\n",
      "  File \"/home/bruno/anaconda3/envs/gpt/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1501, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "  File \"/tmp/ipykernel_61725/4253325660.py\", line 48, in forward\n",
      "    attention_scores = attention_scores.masked_fill(self.causal_mask == 0, -np.inf)\n",
      "RuntimeError: The size of tensor a (80) must match the size of tensor b (4) at non-singleton dimension 2\n",
      "\n",
      "======================================================================\n",
      "ERROR: test_multi_head_attention_forward (__main__.MultiHeadAttentionTest)\n",
      "----------------------------------------------------------------------\n",
      "Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_61725/1695720884.py\", line 130, in test_multi_head_attention_forward\n",
      "    output, _ = self.model(input_tensor)\n",
      "  File \"/home/bruno/anaconda3/envs/gpt/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1501, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "  File \"/tmp/ipykernel_61725/815712447.py\", line 20, in forward\n",
      "    attention_results = [attention(x, pad_mask)[0] for attention in self.attentions]\n",
      "  File \"/tmp/ipykernel_61725/815712447.py\", line 20, in <listcomp>\n",
      "    attention_results = [attention(x, pad_mask)[0] for attention in self.attentions]\n",
      "  File \"/home/bruno/anaconda3/envs/gpt/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1501, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "  File \"/tmp/ipykernel_61725/4253325660.py\", line 48, in forward\n",
      "    attention_scores = attention_scores.masked_fill(self.causal_mask == 0, -np.inf)\n",
      "RuntimeError: The size of tensor a (80) must match the size of tensor b (2) at non-singleton dimension 2\n",
      "\n",
      "======================================================================\n",
      "ERROR: test_multi_head_attention_loss (__main__.MultiHeadAttentionTest)\n",
      "----------------------------------------------------------------------\n",
      "Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_61725/1695720884.py\", line 147, in test_multi_head_attention_loss\n",
      "    output, _ = self.model(input_tensor)\n",
      "  File \"/home/bruno/anaconda3/envs/gpt/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1501, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "  File \"/tmp/ipykernel_61725/815712447.py\", line 20, in forward\n",
      "    attention_results = [attention(x, pad_mask)[0] for attention in self.attentions]\n",
      "  File \"/tmp/ipykernel_61725/815712447.py\", line 20, in <listcomp>\n",
      "    attention_results = [attention(x, pad_mask)[0] for attention in self.attentions]\n",
      "  File \"/home/bruno/anaconda3/envs/gpt/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1501, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "  File \"/tmp/ipykernel_61725/4253325660.py\", line 48, in forward\n",
      "    attention_scores = attention_scores.masked_fill(self.causal_mask == 0, -np.inf)\n",
      "RuntimeError: The size of tensor a (80) must match the size of tensor b (2) at non-singleton dimension 2\n",
      "\n",
      "----------------------------------------------------------------------\n",
      "Ran 9 tests in 0.235s\n",
      "\n",
      "FAILED (errors=5)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<unittest.main.TestProgram at 0x7fbe8d2cbf40>"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# This will run the test in the notebook\n",
    "RUN_UNIT_TESTS and unittest.main(argv=[\"\"], exit=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "gpt",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
